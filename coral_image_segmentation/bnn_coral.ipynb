{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils.prepare as prepare\n",
    "import utils.models as models\n",
    "import utils.LDA as LDA\n",
    "import utils.fast_test as fast_test\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import utils.plot as plot\n",
    "import heapq\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from tensorflow_probability.python.layers import DenseVariational, DenseReparameterization, DenseFlipout, Convolution2DFlipout, Convolution2DReparameterization\n",
    "from tensorflow_probability.python.layers import DistributionLambda\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Activation, LeakyReLU,Conv2D, MaxPooling2D,Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.optimizers import *\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0-dev20191014\n",
      "TensorFlow Probability version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version:', tf.__version__)\n",
    "print('TensorFlow Probability version:', tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 # GPU memory\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(txtfolder_name,imagefloder_name,image_x,image_y):\n",
    "    all_count = 1\n",
    "    all_label = np.zeros(1,dtype=np.int)\n",
    "    image_data = np.zeros([1,30,30,3],dtype=np.uint8)\n",
    "    read_files = glob.glob(str('./')+txtfolder_name+str('/*.txt'))\n",
    "    for name in read_files:\n",
    "        name = name.split(\"/\")[2]\n",
    "        name = name.split(\".\")[0]\n",
    "        path_txt = str('./')+txtfolder_name+str('/')+name+str('.txt')\n",
    "        path_image = str('./')+ imagefloder_name+str('/')+name+str('.jpg')\n",
    "        new_image_data,label = generate_signal_imagedata(path_txt,path_image,image_x,image_y)\n",
    "        all_label = np.hstack((all_label,label))\n",
    "        image_data = np.vstack((image_data,new_image_data))\n",
    "        print(\"Image {0} is finish \".format(all_count))\n",
    "        all_count = all_count+1\n",
    "    final_data = image_data[1:,:,:,:]\n",
    "    final_label = all_label[1:]\n",
    "    return final_data,final_label\n",
    "\n",
    "def generate_signal_imagedata(path_txt,path_image,image_x,image_y):\n",
    "    txt_file = open(path_txt)\n",
    "    text = txt_file.readlines()[2:]\n",
    "    count_points = len(text)\n",
    "    \n",
    "    crop_length = 30\n",
    "    crop_width = 30\n",
    "    all_image = np.zeros([count_points,crop_length,crop_width,3],dtype=np.uint8)\n",
    "    label = np.zeros(count_points,dtype=np.int)\n",
    "    crop_x = int(crop_length/2)\n",
    "    crop_y = int(crop_width/2)\n",
    "    image = imread(path_image)\n",
    "    for i in range(count_points):\n",
    "        text_piece = text[i]\n",
    "        text_element = text_piece.split(',')\n",
    "        l_x = int(float(text_element[0]))\n",
    "        l_y = int(float(text_element[1]))\n",
    "        label[i] = int(text_element[2])\n",
    "        if(l_x-crop_x <0):\n",
    "            l_x = crop_x\n",
    "        if(l_y-crop_y <0):\n",
    "            l_y = crop_y\n",
    "        if(l_x+crop_x >image_y):\n",
    "            l_x = image_y-15\n",
    "        if(l_y+crop_y >image_x):\n",
    "            l_y =image_x-15\n",
    "        all_image[i,:,:,:] = image[l_y-15:l_y+15,l_x-15:l_x+15]\n",
    "    txt_file.close()\n",
    "    return all_image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading coral dataset\n",
      "Image 1 is finish \n",
      "Image 2 is finish \n",
      "Image 3 is finish \n",
      "Image 4 is finish \n",
      "Image 5 is finish \n",
      "Image 6 is finish \n",
      "Image 7 is finish \n",
      "Image 8 is finish \n",
      "Image 9 is finish \n",
      "Image 10 is finish \n",
      "Image 11 is finish \n",
      "Image 12 is finish \n",
      "Image 13 is finish \n",
      "Image 14 is finish \n",
      "Image 15 is finish \n",
      "Image 16 is finish \n",
      "Image 17 is finish \n",
      "Image 18 is finish \n",
      "Image 19 is finish \n",
      "Image 20 is finish \n",
      "Image 21 is finish \n",
      "Image 22 is finish \n",
      "Image 23 is finish \n",
      "Image 24 is finish \n",
      "Image 25 is finish \n",
      "Image 26 is finish \n",
      "Image 27 is finish \n",
      "Image 28 is finish \n",
      "Image 29 is finish \n",
      "Image 30 is finish \n",
      "Image 31 is finish \n",
      "Image 32 is finish \n",
      "Image 33 is finish \n",
      "Image 34 is finish \n",
      "Image 35 is finish \n",
      "Image 36 is finish \n",
      "Image 37 is finish \n",
      "Image 38 is finish \n",
      "Image 39 is finish \n",
      "Image 40 is finish \n",
      "Image 41 is finish \n",
      "Image 42 is finish \n",
      "Image 43 is finish \n",
      "Image 44 is finish \n",
      "Image 45 is finish \n",
      "Image 46 is finish \n",
      "Image 47 is finish \n",
      "Image 48 is finish \n",
      "Image 49 is finish \n",
      "Image 50 is finish \n",
      "Image 51 is finish \n",
      "Image 52 is finish \n",
      "Image 53 is finish \n",
      "Image 54 is finish \n",
      "Image 55 is finish \n",
      "Image 56 is finish \n",
      "Image 57 is finish \n",
      "Image 58 is finish \n",
      "Image 59 is finish \n",
      "Image 60 is finish \n",
      "Image 61 is finish \n",
      "Image 62 is finish \n",
      "Image 63 is finish \n",
      "Image 64 is finish \n",
      "Image 65 is finish \n",
      "Image 66 is finish \n",
      "Image 67 is finish \n",
      "Image 68 is finish \n",
      "Image 69 is finish \n",
      "Image 70 is finish \n",
      "Image 71 is finish \n",
      "Image 72 is finish \n",
      "Image 73 is finish \n",
      "Image 74 is finish \n",
      "Image 75 is finish \n",
      "Image 76 is finish \n",
      "Image 77 is finish \n",
      "Image 78 is finish \n",
      "Image 79 is finish \n",
      "Image 80 is finish \n",
      "Image 81 is finish \n",
      "Image 82 is finish \n",
      "Image 83 is finish \n",
      "Image 84 is finish \n",
      "Image 85 is finish \n",
      "Image 86 is finish \n",
      "Image 87 is finish \n",
      "Image 88 is finish \n",
      "Image 89 is finish \n",
      "Image 90 is finish \n",
      "Image 91 is finish \n",
      "Image 92 is finish \n",
      "Image 93 is finish \n",
      "Image 94 is finish \n",
      "Image 95 is finish \n",
      "Image 96 is finish \n",
      "Image 97 is finish \n",
      "Image 98 is finish \n",
      "Image 99 is finish \n",
      "Image 100 is finish \n",
      "Image 101 is finish \n",
      "Image 102 is finish \n",
      "Image 103 is finish \n",
      "Image 104 is finish \n",
      "Image 105 is finish \n",
      "Image 106 is finish \n",
      "Image 107 is finish \n",
      "Image 108 is finish \n",
      "Image 109 is finish \n",
      "Image 110 is finish \n",
      "Image 111 is finish \n",
      "Image 112 is finish \n",
      "Image 113 is finish \n",
      "Image 114 is finish \n",
      "Image 115 is finish \n",
      "Image 116 is finish \n",
      "Image 117 is finish \n",
      "Image 118 is finish \n",
      "Image 119 is finish \n",
      "Image 120 is finish \n"
     ]
    }
   ],
   "source": [
    "print('Loading coral dataset')\n",
    "data2012_raw_data,data2012_raw_label = load_data('2012data_label augmentation(m=300)','2012image',1536,2048)\n",
    "#data2012_area_data,data2012_area_label = load_data('2012area','2012image',1536,2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66000, 30, 30, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2012_raw_data.shape\n",
    "#data2012_area_data.shape\n",
    "#data2012_all = np.vstack((data2012_raw_data,data2012_area_data))\n",
    "#data2012_all_label = np.hstack((data2012_raw_label,data2012_area_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2012_all_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-51ef26af767e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata2012_all_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data2012_all_label' is not defined"
     ]
    }
   ],
   "source": [
    "data2012_all_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patch_image = prepare.image2patch(\"2012image\",30,[1532,2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shuffle(data,label):\n",
    "    data = data.reshape(-1,2700)\n",
    "    data, label = shuffle(data, label)\n",
    "    shuffle_data = data.reshape(-1,30,30,3)\n",
    "    return shuffle_data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66000, 30, 30, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_data,shuffle_label = data_shuffle(data2012_raw_data,data2012_raw_label)\n",
    "shuffle_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = shuffle_data[0:12000]\n",
    "X_test = shuffle_data[12000:13200]\n",
    "y_train = shuffle_label[0:12000]\n",
    "y_test = shuffle_label[12000:13200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 6\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "n_train = X_train.shape[0]\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_class)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (12000, 30, 30, 3)\n",
      "y_train.shape = (12000, 6)\n",
      "X_test.shape = (1200, 30, 30, 3)\n",
      "y_test.shape = (1200, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.47058824, 0.28235295, 0.27450982],\n",
       "        [0.44313726, 0.27058825, 0.26666668],\n",
       "        [0.41568628, 0.25882354, 0.25882354],\n",
       "        ...,\n",
       "        [0.5647059 , 0.3647059 , 0.38431373],\n",
       "        [0.5294118 , 0.32941177, 0.31764707],\n",
       "        [0.49803922, 0.30588236, 0.2901961 ]],\n",
       "\n",
       "       [[0.47058824, 0.29803923, 0.28627452],\n",
       "        [0.44705883, 0.2901961 , 0.28235295],\n",
       "        [0.42745098, 0.2784314 , 0.26666668],\n",
       "        ...,\n",
       "        [0.46666667, 0.2509804 , 0.27058825],\n",
       "        [0.44705883, 0.25490198, 0.23529412],\n",
       "        [0.43529412, 0.2509804 , 0.22745098]],\n",
       "\n",
       "       [[0.4745098 , 0.3254902 , 0.2901961 ],\n",
       "        [0.4509804 , 0.32156864, 0.28627452],\n",
       "        [0.42745098, 0.3137255 , 0.28235295],\n",
       "        ...,\n",
       "        [0.41568628, 0.2       , 0.21176471],\n",
       "        [0.40392157, 0.21960784, 0.19607843],\n",
       "        [0.41568628, 0.23137255, 0.2       ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.38431373, 0.25882354, 0.2627451 ],\n",
       "        [0.4117647 , 0.25882354, 0.27058825],\n",
       "        [0.41960785, 0.25490198, 0.2627451 ],\n",
       "        ...,\n",
       "        [0.47843137, 0.4862745 , 0.39215687],\n",
       "        [0.5372549 , 0.49019608, 0.39607844],\n",
       "        [0.5686275 , 0.5137255 , 0.4117647 ]],\n",
       "\n",
       "       [[0.40784314, 0.28235295, 0.29411766],\n",
       "        [0.4392157 , 0.28627452, 0.30588236],\n",
       "        [0.43529412, 0.27058825, 0.28627452],\n",
       "        ...,\n",
       "        [0.4627451 , 0.48235294, 0.39215687],\n",
       "        [0.4862745 , 0.52156866, 0.4       ],\n",
       "        [0.5176471 , 0.54509807, 0.42352942]],\n",
       "\n",
       "       [[0.42745098, 0.28627452, 0.3019608 ],\n",
       "        [0.44705883, 0.28627452, 0.3019608 ],\n",
       "        [0.45490196, 0.27058825, 0.29411766],\n",
       "        ...,\n",
       "        [0.49803922, 0.5176471 , 0.42745098],\n",
       "        [0.5254902 , 0.56078434, 0.44705883],\n",
       "        [0.59607846, 0.61960787, 0.50980395]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_test.shape =\", X_test.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "\n",
    "plt.imshow(X_train[25, :, :, :])\n",
    "X_train[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xyu/anaconda3/envs/tensorflow_gpu/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:104: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30, 30, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_flipout (Conv2DFlipou (None, 30, 30, 32)        1761      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_flipout_1 (Conv2DFlip (None, 28, 28, 32)        18465     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_flipout_2 (Conv2DFlip (None, 14, 14, 64)        36929     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_flipout_3 (Conv2DFlip (None, 12, 12, 64)        73793     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_flipout_4 (Conv2DFlip (None, 6, 6, 128)         147585    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_flipout_5 (Conv2DFlip (None, 4, 4, 128)         295041    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_flipout (DenseFlipout) (None, 512)               524801    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_flipout_1 (DenseFlipou (None, 6)                 6151      \n",
      "=================================================================\n",
      "Total params: 1,105,422\n",
      "Trainable params: 1,104,966\n",
      "Non-trainable params: 456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "lr = 1e-3\n",
    "def neg_log_likelihood_with_logits(y_true, y_pred):\n",
    "    y_pred_dist = tfp.distributions.Categorical(logits=y_pred)\n",
    "    return -tf.reduce_mean(y_pred_dist.log_prob(tf.argmax(y_true, axis=-1)))\n",
    "\n",
    "def get_kernel_divergence_fn(train_size, w=1.0):\n",
    "    \"\"\"\n",
    "    Get the kernel Kullback-Leibler divergence function\n",
    "\n",
    "    # Arguments\n",
    "        train_size (int): size of the training dataset for normalization\n",
    "        w (float): weight to the function\n",
    "\n",
    "    # Returns\n",
    "        kernel_divergence_fn: kernel Kullback-Leibler divergence function\n",
    "    \"\"\"\n",
    "    def kernel_divergence_fn(q, p, _):  # need the third ignorable argument\n",
    "        kernel_divergence = tfp.distributions.kl_divergence(q, p) / tf.cast(train_size, tf.float32)\n",
    "        return w * kernel_divergence\n",
    "    return kernel_divergence_fn\n",
    "\n",
    "def add_kl_weight(layer, train_size, w_value=1.0):\n",
    "    w = layer.add_weight(name=layer.name+'/kl_loss_weight', shape=(),\n",
    "                         initializer=tf.initializers.constant(w_value), trainable=False)\n",
    "    layer.kernel_divergence_fn = get_kernel_divergence_fn(train_size, w)\n",
    "    return layer\n",
    "\n",
    "def build_bayesian_bcnn_model(input_shape, train_size):\n",
    "    model_in = Input(shape=input_shape)\n",
    "    conv_1 = Convolution2DFlipout(32, kernel_size=(3, 3), padding=\"same\",\n",
    "                                  kernel_divergence_fn=None)\n",
    "    conv_1 = add_kl_weight(conv_1, train_size)\n",
    "    x = conv_1(model_in)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    conv_2 = Convolution2DFlipout(32, kernel_size=(3, 3),\n",
    "                                  kernel_divergence_fn=None)\n",
    "    conv_2 = add_kl_weight(conv_2, train_size)\n",
    "    x = conv_2(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    \n",
    "    conv_3 = Convolution2DFlipout(64, kernel_size=(3, 3), padding=\"same\",\n",
    "                                  kernel_divergence_fn=None)\n",
    "    conv_3 = add_kl_weight(conv_3, train_size)\n",
    "    x = conv_3(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    conv_4 = Convolution2DFlipout(64, kernel_size=(3, 3),\n",
    "                                  kernel_divergence_fn=None)\n",
    "    conv_4 = add_kl_weight(conv_4, train_size)\n",
    "    x = conv_4(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    \n",
    "    conv_5 = Convolution2DFlipout(128, kernel_size=(3, 3), padding=\"same\",\n",
    "                                  kernel_divergence_fn=None)\n",
    "    conv_5 = add_kl_weight(conv_5, train_size)\n",
    "    x = conv_5(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    conv_6 = Convolution2DFlipout(128, kernel_size=(3, 3),\n",
    "                                  kernel_divergence_fn=None)\n",
    "    conv_6 = add_kl_weight(conv_6, train_size)\n",
    "    x = conv_6(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    dense_1 = DenseFlipout(512, activation='relu',\n",
    "                           kernel_divergence_fn=None)\n",
    "    dense_1 = add_kl_weight(dense_1, train_size)\n",
    "    x = dense_1(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    dense_2 = DenseFlipout(6, activation=None,\n",
    "                           kernel_divergence_fn=None)\n",
    "    dense_2 = add_kl_weight(dense_2, train_size)\n",
    "    model_out = dense_2(x)  # logits\n",
    "    model = Model(model_in, model_out)\n",
    "    return model\n",
    "    \n",
    "bcnn_model = build_bayesian_bcnn_model(X_train.shape[1:], 50000)\n",
    "bcnn_model.compile(loss=neg_log_likelihood_with_logits, optimizer=tf.keras.optimizers.Adam(lr), metrics=['acc'],\n",
    "                   experimental_run_tf_function=False)\n",
    "bcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bcnn_model.load_weights(\"model_coral.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = bcnn_model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, \n",
    "                      verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn_model.save_weights('./model_weights/bcnn_12000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn_model.load_weights('./model_weights/bcnn_6000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "qmeans = []\n",
    "qstds = []\n",
    "pmeans = []\n",
    "pstds = []\n",
    "for i, layer in enumerate(bcnn_model.layers):\n",
    "    try:\n",
    "      q = layer.kernel_posterior\n",
    "      p = layer.kernel_prior\n",
    "    except AttributeError:\n",
    "      continue\n",
    "    names.append(\"Layer {}\".format(i))\n",
    "    qmeans.append(q.mean())\n",
    "    qstds.append(q.stddev())\n",
    "    pmeans.append(p.mean())\n",
    "    pstds.append(p.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig,axs = plt.subplots(1,2,figsize=(10, 5))\n",
    "for n, qm in zip(names, qmeans):\n",
    "    qm = np.array(qm)\n",
    "    sns.distplot(qm.flatten(), ax = axs[0],label=n)\n",
    "#fig.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "axs[0].legend()\n",
    "axs[0].set_title('weight means in each layer')\n",
    "\n",
    "for n, qs in zip(names, qstds):\n",
    "    qs = np.array(qs)\n",
    "    sns.distplot(qs.flatten(), ax = axs[1],label=n)\n",
    "axs[1].legend()\n",
    "axs[1].set_title('weight stddevs in each layer')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_coral(testimage):\n",
    "    count = 0 \n",
    "    #blue = np.array([0,0,255], dtype=np.uint8)\n",
    "    test = np.uint8(testimage)\n",
    "    f = np.where(test[:,:,2]==255)\n",
    "    count = len(f[0])\n",
    "    all_pixel = test.shape[0]*test.shape[1]\n",
    "    coral_percent = (count/all_pixel)*100 \n",
    "    coral_percent = round(coral_percent,2)\n",
    "    return coral_percent\n",
    "\n",
    "\n",
    "def fun(x,y):\n",
    "    f = test_image[x:x+30,y:y+30]\n",
    "    f = f.reshape(2700)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '201208172_T-12-58-58_Dive_01_041'\n",
    "path_image = './2012image/'+str(name)+'.jpg'\n",
    "file_image ='2012image'\n",
    "name_image = str(name)\n",
    "stride = 6\n",
    "test_image = imread(path_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_palindrome = np.frompyfunc(fun, 2, 1)\n",
    "x = np.arange(0,test_image.shape[0] - 30+1, stride)\n",
    "y = np.arange(0,test_image.shape[1] - 30+1, stride)\n",
    "X,Y = np.meshgrid(x, y)\n",
    "#%%\n",
    "zs = check_palindrome(np.ravel(X.T), np.ravel(Y.T))\n",
    "fs = np.concatenate(zs,axis=0).astype(np.uint8)\n",
    "image_all_patches = fs.reshape(len(x)*len(y),30,30,3)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc_run = 2\n",
    "y_pred_logits_list = [bcnn_model.predict(image_all_patches,verbose=1) for _ in range(n_mc_run)]  # a list of predicted logits\n",
    "y_pred_prob_all = np.concatenate([softmax(y, axis=-1)[:, :, np.newaxis] for y in y_pred_logits_list], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_prob_all.shape\n",
    "y_mean_pred = np.mean(y_pred_prob_all,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2d(arr: np.ndarray,savenum):\n",
    "    plt.imshow(arr, cmap=\"YlGnBu\")#,vmin=0, vmax=0.1)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    #plt.savefig(\"output_\"+str(savenum)+\".pdf\")\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "def array2heatmap(array,x,y,stride,savenum):\n",
    "    y_pred = array[:,0]\n",
    "    y_pred = y_pred.reshape(x,y)\n",
    "    array_y_pred = y_pred.repeat(stride,axis = 0).repeat(stride, axis = 1)\n",
    "    heatmap2d(array_y_pred,savenum)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2heatmap(y_mean_pred,252,337,6,'12000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2d(arr: np.ndarray,savenum):\n",
    "    plt.imshow(arr, cmap=\"YlGnBu\")#,vmin=0, vmax=0.1)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    #plt.savefig(\"output_\"+str(savenum)+\".pdf\")\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "def array2heatmap(array,x,y,stride,savenum):\n",
    "    y_pred = array[:,0]\n",
    "    y_pred = y_pred.reshape(x,y)\n",
    "    array_y_pred = y_pred.repeat(stride,axis = 0).repeat(stride, axis = 1)\n",
    "    heatmap2d(array_y_pred,savenum)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc_run = 1\n",
    "med_prob_thres = 0.2\n",
    "\n",
    "y_pred_logits_list = [bcnn_model.predict(X_test,verbose=1) for _ in range(n_mc_run)]  # a list of predicted logits\n",
    "y_pred_prob_all = np.concatenate([softmax(y, axis=-1)[:, :, np.newaxis] for y in y_pred_logits_list], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_train = np.argmax(y_pred_prob_all[:,:,0],axis=-1)\n",
    "g = np.where(y_pre_train==np.argmax(y_test,axis=-1))\n",
    "len(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"all_patches_result.npy\",y_pred_prob_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[int(np.median(y) >= 0.2) for y in y_pred_prob] for y_pred_prob in y_pred_prob_all]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_hist(y_pred, n_class, n_mc_run, n_bins=30, med_prob_thres=0.2, n_subplot_rows=4, figsize=(10, 15)):\n",
    "    bins = np.logspace(-n_bins, 0, n_bins+1)\n",
    "    fig, ax = plt.subplots(n_subplot_rows, n_class // n_subplot_rows + 1, figsize=figsize)\n",
    "    for i in range(n_subplot_rows):\n",
    "        for j in range(n_class // n_subplot_rows + 1):\n",
    "            idx = i * (n_class // n_subplot_rows + 1) + j\n",
    "            if idx < n_class:\n",
    "                ax[i, j].hist(y_pred[idx], bins)\n",
    "                ax[i, j].set_xscale('log')\n",
    "                ax[i, j].set_ylim([0, n_mc_run])\n",
    "                ax[i, j].title.set_text(\"{} (median prob: {:.2f}) ({})\".format(str(idx),\n",
    "                                                                               np.median(y_pred[idx]),\n",
    "                                                                               str(np.median(y_pred[idx]) >= med_prob_thres)))\n",
    "            else:\n",
    "                ax[i, j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coral_test = np.where(np.argmax(y_test,axis=-1)==0)[0]\n",
    "pre_prob = np.zeros(len(true_coral_test))\n",
    "for i, index in enumerate(true_coral_test):\n",
    "    pre_prob[i] = (np.sum(y_pred_prob_all[index][0]))/500\n",
    "\n",
    "index_coral = np.argsort(pre_prob)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_large = pre_prob[pre_prob>0.5]\n",
    "index_large = np.argsort(prob_large)[::-1]\n",
    "index_show = np.int16(np.where(pre_prob==prob_large[index_large[0]]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = true_coral_test[index_show]\n",
    "plt.imshow(X_test[idx, :, :, :])\n",
    "print(\"True label of the test sample {}: {}\".format(idx, np.argmax(y_test[idx], axis=-1)))\n",
    "\n",
    "plot_pred_hist(y_pred_prob_all[idx], n_class, n_mc_run, med_prob_thres=med_prob_thres)\n",
    "\n",
    "#if any(y_pred[idx]):\n",
    "print(\"Predicted label of the test sample {}: {}\".format(idx, np.argmax(y_pred[idx], axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.86000000000001,
   "position": {
    "height": "406.86px",
    "left": "594px",
    "right": "20px",
    "top": "-8px",
    "width": "273px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
