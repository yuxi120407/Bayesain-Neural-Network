{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras import activations, initializers\n",
    "from keras.layers import Layer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def f(x, sigma):\n",
    "    epsilon = np.random.randn(*x.shape) * sigma\n",
    "    return 10 * np.sin(2 * np.pi * (x)) + epsilon\n",
    "\n",
    "train_size = 32\n",
    "noise = 1.0\n",
    "\n",
    "X = np.linspace(-0.5, 0.5, train_size).reshape(-1, 1)\n",
    "y = f(X, sigma=noise)\n",
    "y_true = f(X, sigma=0.0)\n",
    "\n",
    "plt.scatter(X, y, marker='+', label='Training data')\n",
    "plt.plot(X, y_true, label='Truth')\n",
    "plt.title('Noisy training data and ground truth')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3 # 占用GPU90%的显存 \n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.compat.v1.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixture_prior_params(sigma_1, sigma_2, pi, return_sigma=False):\n",
    "    params = K.variable([sigma_1, sigma_2, pi], name='mixture_prior_params')\n",
    "    sigma = np.sqrt(pi * sigma_1 ** 2 + (1 - pi) * sigma_2 ** 2)\n",
    "    return params, sigma\n",
    "\n",
    "def log_mixture_prior_prob(w):\n",
    "    comp_1_dist = tfp.distributions.Normal(0.0, prior_params[0])\n",
    "    comp_2_dist = tfp.distributions.Normal(0.0, prior_params[1])\n",
    "    comp_1_weight = prior_params[2]    \n",
    "    return K.log(comp_1_weight * comp_1_dist.prob(w) + (1 - comp_1_weight) * comp_2_dist.prob(w))    \n",
    "\n",
    "# Mixture prior parameters shared across DenseVariational layer instances\n",
    "prior_params, prior_sigma = mixture_prior_params(sigma_1=1.0, sigma_2=0.1, pi=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4560701700396552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xyu/anaconda3/envs/tensorflow_new/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "class DenseVariational(Layer):\n",
    "    def __init__(self, output_dim, kl_loss_weight, activation=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.kl_loss_weight = kl_loss_weight\n",
    "        self.activation = activations.get(activation)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):  \n",
    "        self._trainable_weights.append(prior_params) \n",
    "\n",
    "        self.kernel_mu = self.add_weight(name='kernel_mu', \n",
    "                                         shape=(input_shape[1], self.output_dim),\n",
    "                                         initializer=initializers.normal(stddev=prior_sigma),\n",
    "                                         trainable=True)\n",
    "        self.bias_mu = self.add_weight(name='bias_mu', \n",
    "                                       shape=(self.output_dim,),\n",
    "                                       initializer=initializers.normal(stddev=prior_sigma),\n",
    "                                       trainable=True)\n",
    "        self.kernel_rho = self.add_weight(name='kernel_rho', \n",
    "                                          shape=(input_shape[1], self.output_dim),\n",
    "                                          initializer=initializers.constant(0.0),\n",
    "                                          trainable=True)\n",
    "        self.bias_rho = self.add_weight(name='bias_rho', \n",
    "                                        shape=(self.output_dim,),\n",
    "                                        initializer=initializers.constant(0.0),\n",
    "                                        trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        kernel_sigma = tf.math.softplus(self.kernel_rho)\n",
    "        kernel = self.kernel_mu + kernel_sigma * tf.random.normal(self.kernel_mu.shape)\n",
    "\n",
    "        bias_sigma = tf.math.softplus(self.bias_rho)\n",
    "        bias = self.bias_mu + bias_sigma * tf.random.normal(self.bias_mu.shape)\n",
    "                \n",
    "        self.add_loss(self.kl_loss(kernel, self.kernel_mu, kernel_sigma) + \n",
    "                      self.kl_loss(bias, self.bias_mu, bias_sigma))\n",
    "        \n",
    "        return self.activation(K.dot(x, kernel) + bias)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    def kl_loss(self, w, mu, sigma):\n",
    "        variational_dist = tfp.distributions.Normal(mu, sigma)\n",
    "        return kl_loss_weight * K.sum(variational_dist.log_prob(w) - log_mixture_prior_prob(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-ca8fdf3e7707>:7: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/xyu/anaconda3/envs/tensorflow_new/lib/python3.6/site-packages/tensorflow_core/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "batch_size = train_size\n",
    "num_batches = train_size / batch_size\n",
    "kl_loss_weight = 1.0 / num_batches\n",
    "\n",
    "x_in = Input(shape=(1,))\n",
    "x = DenseVariational(20, kl_loss_weight=kl_loss_weight, activation='relu')(x_in)\n",
    "x = DenseVariational(20, kl_loss_weight=kl_loss_weight, activation='relu')(x)\n",
    "x = DenseVariational(1, kl_loss_weight=kl_loss_weight)(x)\n",
    "\n",
    "model = Model(x_in, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_variational_1 (DenseVa (None, 20)                83        \n",
      "_________________________________________________________________\n",
      "dense_variational_2 (DenseVa (None, 20)                843       \n",
      "_________________________________________________________________\n",
      "dense_variational_3 (DenseVa (None, 1)                 45        \n",
      "=================================================================\n",
      "Total params: 965\n",
      "Trainable params: 965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 252.7246 - mse: 8.3761\n",
      "Epoch 2/1500\n",
      "32/32 [==============================] - 0s 156us/step - loss: 271.7225 - mse: 8.5817\n",
      "Epoch 3/1500\n",
      "32/32 [==============================] - 0s 141us/step - loss: 432.2337 - mse: 19.5402\n",
      "Epoch 4/1500\n",
      "32/32 [==============================] - 0s 138us/step - loss: 299.5752 - mse: 10.9023\n",
      "Epoch 5/1500\n",
      "32/32 [==============================] - 0s 147us/step - loss: 300.7024 - mse: 11.8437\n",
      "Epoch 6/1500\n",
      "32/32 [==============================] - 0s 288us/step - loss: 282.1589 - mse: 9.4834\n",
      "Epoch 7/1500\n",
      "32/32 [==============================] - 0s 155us/step - loss: 282.1868 - mse: 10.0196\n",
      "Epoch 8/1500\n",
      "32/32 [==============================] - 0s 143us/step - loss: 248.1147 - mse: 8.0690\n",
      "Epoch 9/1500\n",
      "32/32 [==============================] - 0s 142us/step - loss: 268.3594 - mse: 9.2022\n",
      "Epoch 10/1500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 250.4052 - mse: 8.7333\n",
      "Epoch 11/1500\n",
      "32/32 [==============================] - 0s 133us/step - loss: 263.2576 - mse: 8.3088\n",
      "Epoch 12/1500\n",
      "32/32 [==============================] - 0s 132us/step - loss: 312.9674 - mse: 12.8501\n",
      "Epoch 13/1500\n",
      "32/32 [==============================] - 0s 130us/step - loss: 254.1900 - mse: 7.8942\n",
      "Epoch 14/1500\n",
      "32/32 [==============================] - 0s 136us/step - loss: 231.0314 - mse: 6.8272\n",
      "Epoch 15/1500\n",
      "32/32 [==============================] - 0s 138us/step - loss: 226.0131 - mse: 6.7700\n",
      "Epoch 16/1500\n",
      "32/32 [==============================] - 0s 131us/step - loss: 344.5305 - mse: 14.0388\n",
      "Epoch 17/1500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 234.9523 - mse: 7.3133\n",
      "Epoch 18/1500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 240.9194 - mse: 7.6920\n",
      "Epoch 19/1500\n",
      "32/32 [==============================] - 0s 130us/step - loss: 310.1818 - mse: 12.3130\n",
      "Epoch 20/1500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 270.3346 - mse: 9.1848\n",
      "Epoch 21/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 282.5680 - mse: 9.9575\n",
      "Epoch 22/1500\n",
      "32/32 [==============================] - 0s 133us/step - loss: 323.0725 - mse: 12.4098\n",
      "Epoch 23/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 275.9124 - mse: 8.8552\n",
      "Epoch 24/1500\n",
      "32/32 [==============================] - 0s 139us/step - loss: 289.4319 - mse: 10.3916\n",
      "Epoch 25/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 288.3398 - mse: 9.8188\n",
      "Epoch 26/1500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 274.1273 - mse: 9.3053\n",
      "Epoch 27/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 267.8975 - mse: 8.9987\n",
      "Epoch 28/1500\n",
      "32/32 [==============================] - 0s 141us/step - loss: 467.4037 - mse: 21.9781\n",
      "Epoch 29/1500\n",
      "32/32 [==============================] - 0s 146us/step - loss: 435.1139 - mse: 20.0440\n",
      "Epoch 30/1500\n",
      "32/32 [==============================] - 0s 135us/step - loss: 274.7180 - mse: 9.7963\n",
      "Epoch 31/1500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 277.7611 - mse: 9.3517\n",
      "Epoch 32/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 237.9654 - mse: 6.9531\n",
      "Epoch 33/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 254.6799 - mse: 7.9013\n",
      "Epoch 34/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 254.9283 - mse: 7.5420\n",
      "Epoch 35/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 330.6188 - mse: 13.0635\n",
      "Epoch 36/1500\n",
      "32/32 [==============================] - 0s 129us/step - loss: 284.9986 - mse: 8.6720\n",
      "Epoch 37/1500\n",
      "32/32 [==============================] - 0s 124us/step - loss: 233.8551 - mse: 7.2255\n",
      "Epoch 38/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 277.2259 - mse: 9.4368\n",
      "Epoch 39/1500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 261.3348 - mse: 8.2692\n",
      "Epoch 40/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 328.3641 - mse: 12.5101\n",
      "Epoch 41/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 311.9260 - mse: 12.0562\n",
      "Epoch 42/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 249.3610 - mse: 8.0798\n",
      "Epoch 43/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 240.2867 - mse: 6.8932\n",
      "Epoch 44/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 254.0513 - mse: 7.6513\n",
      "Epoch 45/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 530.7305 - mse: 25.9465\n",
      "Epoch 46/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 264.2943 - mse: 8.1384\n",
      "Epoch 47/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 337.5449 - mse: 13.1083\n",
      "Epoch 48/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 258.8423 - mse: 8.1503\n",
      "Epoch 49/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 386.1826 - mse: 16.1097\n",
      "Epoch 50/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 251.4703 - mse: 8.3746\n",
      "Epoch 51/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 228.6832 - mse: 6.8419\n",
      "Epoch 52/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 254.1365 - mse: 7.0922\n",
      "Epoch 53/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 301.0635 - mse: 10.6588\n",
      "Epoch 54/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 249.1084 - mse: 7.6446\n",
      "Epoch 55/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 430.7760 - mse: 19.0369\n",
      "Epoch 56/1500\n",
      "32/32 [==============================] - 0s 132us/step - loss: 276.8039 - mse: 9.9608\n",
      "Epoch 57/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 239.6178 - mse: 7.5061\n",
      "Epoch 58/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 264.5390 - mse: 8.2173\n",
      "Epoch 59/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 251.4726 - mse: 7.4764\n",
      "Epoch 60/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 255.6259 - mse: 8.2124\n",
      "Epoch 61/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 374.5274 - mse: 16.4691\n",
      "Epoch 62/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 275.5239 - mse: 9.6475\n",
      "Epoch 63/1500\n",
      "32/32 [==============================] - 0s 143us/step - loss: 276.6418 - mse: 8.4987\n",
      "Epoch 64/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 298.0806 - mse: 11.8959\n",
      "Epoch 65/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 273.5863 - mse: 9.1536\n",
      "Epoch 66/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 237.9890 - mse: 6.4279\n",
      "Epoch 67/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 246.0369 - mse: 7.9551\n",
      "Epoch 68/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 251.0658 - mse: 8.0195\n",
      "Epoch 69/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 266.5198 - mse: 8.8152\n",
      "Epoch 70/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 241.6633 - mse: 7.2639\n",
      "Epoch 71/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 277.9588 - mse: 9.2422\n",
      "Epoch 72/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 259.8926 - mse: 8.4343\n",
      "Epoch 73/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 258.8575 - mse: 7.7241\n",
      "Epoch 74/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 272.1863 - mse: 9.2297\n",
      "Epoch 75/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 265.4195 - mse: 8.2310\n",
      "Epoch 76/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 237.2159 - mse: 7.4633\n",
      "Epoch 77/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 243.5537 - mse: 7.5417\n",
      "Epoch 78/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 279.4012 - mse: 9.6460\n",
      "Epoch 79/1500\n",
      "32/32 [==============================] - 0s 138us/step - loss: 258.8316 - mse: 8.6098\n",
      "Epoch 80/1500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 243.6859 - mse: 6.5854\n",
      "Epoch 81/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 279.3643 - mse: 9.8858\n",
      "Epoch 82/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 275.9264 - mse: 9.3163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 245.2124 - mse: 7.5980\n",
      "Epoch 84/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 251.2616 - mse: 8.9220\n",
      "Epoch 85/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 251.3822 - mse: 8.2872\n",
      "Epoch 86/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 308.4640 - mse: 11.5262\n",
      "Epoch 87/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 264.8896 - mse: 8.8767\n",
      "Epoch 88/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 268.3062 - mse: 8.2233\n",
      "Epoch 89/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 265.7657 - mse: 8.8235\n",
      "Epoch 90/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 262.7505 - mse: 7.4507\n",
      "Epoch 91/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 253.0090 - mse: 8.1967\n",
      "Epoch 92/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 277.0348 - mse: 8.8052\n",
      "Epoch 93/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 257.3980 - mse: 8.1914\n",
      "Epoch 94/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 248.6802 - mse: 7.6628\n",
      "Epoch 95/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 282.7311 - mse: 10.3182\n",
      "Epoch 96/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 251.5745 - mse: 8.4084\n",
      "Epoch 97/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 229.1965 - mse: 6.0708\n",
      "Epoch 98/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 274.1714 - mse: 9.9846\n",
      "Epoch 99/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 289.9824 - mse: 9.4100\n",
      "Epoch 100/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 285.4573 - mse: 9.8589\n",
      "Epoch 101/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 287.6619 - mse: 9.8458\n",
      "Epoch 102/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 235.2590 - mse: 6.9950\n",
      "Epoch 103/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 225.7578 - mse: 5.9995\n",
      "Epoch 104/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 343.4628 - mse: 12.8351\n",
      "Epoch 105/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 236.1901 - mse: 7.0082\n",
      "Epoch 106/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 255.2683 - mse: 8.7803\n",
      "Epoch 107/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 260.4374 - mse: 7.7305\n",
      "Epoch 108/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 267.8558 - mse: 8.4061\n",
      "Epoch 109/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 248.5417 - mse: 6.9649\n",
      "Epoch 110/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 326.8778 - mse: 12.0864\n",
      "Epoch 111/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 247.2973 - mse: 7.4452\n",
      "Epoch 112/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 290.1490 - mse: 10.3809\n",
      "Epoch 113/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 251.3425 - mse: 7.8489\n",
      "Epoch 114/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 255.6655 - mse: 7.1275\n",
      "Epoch 115/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 281.3518 - mse: 9.3717\n",
      "Epoch 116/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 285.7312 - mse: 9.0262\n",
      "Epoch 117/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 235.3844 - mse: 6.4458\n",
      "Epoch 118/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 241.2044 - mse: 7.0112\n",
      "Epoch 119/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 260.6342 - mse: 8.3285\n",
      "Epoch 120/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 224.3284 - mse: 6.1858\n",
      "Epoch 121/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 266.1538 - mse: 8.5130\n",
      "Epoch 122/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 248.7626 - mse: 7.5035\n",
      "Epoch 123/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 236.6162 - mse: 6.7429\n",
      "Epoch 124/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 252.7818 - mse: 7.6488\n",
      "Epoch 125/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 283.7812 - mse: 9.0312\n",
      "Epoch 126/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 269.6666 - mse: 8.8879\n",
      "Epoch 127/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 267.5754 - mse: 8.6866\n",
      "Epoch 128/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 253.1969 - mse: 7.4732\n",
      "Epoch 129/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 258.3909 - mse: 8.4254\n",
      "Epoch 130/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 261.2230 - mse: 7.7027\n",
      "Epoch 131/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 275.6206 - mse: 8.0423\n",
      "Epoch 132/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 338.0133 - mse: 13.9127\n",
      "Epoch 133/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 288.2460 - mse: 10.2350\n",
      "Epoch 134/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 247.2106 - mse: 6.9030\n",
      "Epoch 135/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 248.7426 - mse: 7.4864\n",
      "Epoch 136/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 236.1821 - mse: 7.4502\n",
      "Epoch 137/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 244.3487 - mse: 6.5464\n",
      "Epoch 138/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 244.1485 - mse: 7.8588\n",
      "Epoch 139/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 291.4336 - mse: 9.8138\n",
      "Epoch 140/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 296.8930 - mse: 10.2780\n",
      "Epoch 141/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 273.1401 - mse: 8.8213\n",
      "Epoch 142/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 250.7453 - mse: 8.0911\n",
      "Epoch 143/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 605.7087 - mse: 30.2746\n",
      "Epoch 144/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 248.5331 - mse: 7.9193\n",
      "Epoch 145/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 253.9840 - mse: 7.1738\n",
      "Epoch 146/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 234.7302 - mse: 6.3907\n",
      "Epoch 147/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 253.7130 - mse: 7.6418\n",
      "Epoch 148/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 281.7226 - mse: 9.6599\n",
      "Epoch 149/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 263.9487 - mse: 7.6408\n",
      "Epoch 150/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 299.2740 - mse: 10.7995\n",
      "Epoch 151/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 249.4961 - mse: 7.3338\n",
      "Epoch 152/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 301.2997 - mse: 9.7942\n",
      "Epoch 153/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 262.3562 - mse: 7.7440\n",
      "Epoch 154/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 249.3110 - mse: 7.6758\n",
      "Epoch 155/1500\n",
      "32/32 [==============================] - 0s 66us/step - loss: 233.5911 - mse: 7.1765\n",
      "Epoch 156/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 246.2903 - mse: 6.9000\n",
      "Epoch 157/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 243.3565 - mse: 6.5207\n",
      "Epoch 158/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 275.1374 - mse: 8.3492\n",
      "Epoch 159/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 319.4757 - mse: 11.2754\n",
      "Epoch 160/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 233.5997 - mse: 6.9032\n",
      "Epoch 161/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 280.2738 - mse: 9.5819\n",
      "Epoch 162/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 262.3474 - mse: 7.8804\n",
      "Epoch 163/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 247.8974 - mse: 6.6410\n",
      "Epoch 164/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 251.1490 - mse: 7.4608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 278.8400 - mse: 10.0782\n",
      "Epoch 166/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 280.6458 - mse: 9.6004\n",
      "Epoch 167/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 241.4539 - mse: 6.5421\n",
      "Epoch 168/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 245.6852 - mse: 7.0552\n",
      "Epoch 169/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 268.0938 - mse: 7.8922\n",
      "Epoch 170/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 248.9514 - mse: 7.1540\n",
      "Epoch 171/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 222.6920 - mse: 5.6976\n",
      "Epoch 172/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 236.1678 - mse: 6.3406\n",
      "Epoch 173/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 265.7718 - mse: 8.2252\n",
      "Epoch 174/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 290.1475 - mse: 10.4662\n",
      "Epoch 175/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 230.0260 - mse: 7.2718\n",
      "Epoch 176/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 254.0101 - mse: 7.4432\n",
      "Epoch 177/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 259.1237 - mse: 7.6236\n",
      "Epoch 178/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 232.3673 - mse: 6.1825\n",
      "Epoch 179/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 259.9744 - mse: 8.2375\n",
      "Epoch 180/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 270.1455 - mse: 8.7525\n",
      "Epoch 181/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 229.7617 - mse: 6.0544\n",
      "Epoch 182/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 237.0277 - mse: 7.3948\n",
      "Epoch 183/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 294.8838 - mse: 10.2090\n",
      "Epoch 184/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 223.6471 - mse: 6.2366\n",
      "Epoch 185/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 231.3521 - mse: 6.2409\n",
      "Epoch 186/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 262.6894 - mse: 8.1867\n",
      "Epoch 187/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 285.3744 - mse: 9.3431\n",
      "Epoch 188/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 254.0072 - mse: 7.7368\n",
      "Epoch 189/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 228.5282 - mse: 5.5864\n",
      "Epoch 190/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 229.1432 - mse: 5.8871\n",
      "Epoch 191/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 251.2095 - mse: 7.3788\n",
      "Epoch 192/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 700.7479 - mse: 35.7458\n",
      "Epoch 193/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 317.8603 - mse: 10.8229\n",
      "Epoch 194/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 266.1010 - mse: 7.8857\n",
      "Epoch 195/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 288.7152 - mse: 8.5676\n",
      "Epoch 196/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 483.2815 - mse: 21.2663\n",
      "Epoch 197/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 247.2419 - mse: 6.5503\n",
      "Epoch 198/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 245.6557 - mse: 7.2094\n",
      "Epoch 199/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 216.3878 - mse: 5.0608\n",
      "Epoch 200/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 233.6082 - mse: 5.4188\n",
      "Epoch 201/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 244.0856 - mse: 7.0049\n",
      "Epoch 202/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 241.5645 - mse: 7.1664\n",
      "Epoch 203/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 331.9554 - mse: 11.3292\n",
      "Epoch 204/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 234.0140 - mse: 6.4562\n",
      "Epoch 205/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 281.5186 - mse: 8.5296\n",
      "Epoch 206/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 268.8622 - mse: 7.6252\n",
      "Epoch 207/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 242.4821 - mse: 6.0405\n",
      "Epoch 208/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 278.0320 - mse: 8.3779\n",
      "Epoch 209/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 228.3769 - mse: 6.0229\n",
      "Epoch 210/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 269.1770 - mse: 7.3603\n",
      "Epoch 211/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 236.9606 - mse: 5.8000\n",
      "Epoch 212/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 214.1900 - mse: 5.0267\n",
      "Epoch 213/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 245.5858 - mse: 7.7686\n",
      "Epoch 214/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 296.2021 - mse: 9.4113\n",
      "Epoch 215/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 226.2511 - mse: 5.4756\n",
      "Epoch 216/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 234.0428 - mse: 5.7047\n",
      "Epoch 217/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 330.2104 - mse: 12.3761\n",
      "Epoch 218/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 233.8965 - mse: 5.8228\n",
      "Epoch 219/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 290.1533 - mse: 9.4320\n",
      "Epoch 220/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 243.6482 - mse: 6.2238\n",
      "Epoch 221/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 236.9867 - mse: 6.4993\n",
      "Epoch 222/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 216.9510 - mse: 4.9773\n",
      "Epoch 223/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 229.6085 - mse: 5.0976\n",
      "Epoch 224/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 295.0670 - mse: 9.5079\n",
      "Epoch 225/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 317.4050 - mse: 11.3855\n",
      "Epoch 226/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 235.0971 - mse: 6.0224\n",
      "Epoch 227/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 244.4486 - mse: 6.2375\n",
      "Epoch 228/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 259.9554 - mse: 6.8841\n",
      "Epoch 229/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 326.1181 - mse: 12.5218\n",
      "Epoch 230/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 250.3778 - mse: 6.9866\n",
      "Epoch 231/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 213.5618 - mse: 4.5765\n",
      "Epoch 232/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 245.2896 - mse: 5.6089\n",
      "Epoch 233/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 255.3088 - mse: 6.4085\n",
      "Epoch 234/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 280.8801 - mse: 7.7399\n",
      "Epoch 235/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 246.5699 - mse: 6.6767\n",
      "Epoch 236/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 234.8474 - mse: 4.9653\n",
      "Epoch 237/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 282.1367 - mse: 8.9545\n",
      "Epoch 238/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 276.9155 - mse: 8.0824\n",
      "Epoch 239/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 241.2960 - mse: 5.6469\n",
      "Epoch 240/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 261.0840 - mse: 7.0804\n",
      "Epoch 241/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 239.8731 - mse: 5.6655\n",
      "Epoch 242/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 213.2832 - mse: 4.5551\n",
      "Epoch 243/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 294.8676 - mse: 9.2224\n",
      "Epoch 244/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 274.4631 - mse: 7.9115\n",
      "Epoch 245/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 252.2690 - mse: 6.8666\n",
      "Epoch 246/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 207.1796 - mse: 3.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 242.6149 - mse: 5.9919\n",
      "Epoch 248/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 242.2840 - mse: 5.2426\n",
      "Epoch 249/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 233.0520 - mse: 5.1718\n",
      "Epoch 250/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 267.7860 - mse: 7.9609\n",
      "Epoch 251/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 273.7654 - mse: 8.3122\n",
      "Epoch 252/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 240.3308 - mse: 6.4776\n",
      "Epoch 253/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 211.0158 - mse: 3.8906\n",
      "Epoch 254/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 242.2003 - mse: 4.9012\n",
      "Epoch 255/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 284.9410 - mse: 8.9995\n",
      "Epoch 256/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 241.3553 - mse: 6.4312\n",
      "Epoch 257/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 274.0861 - mse: 8.8024\n",
      "Epoch 258/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 214.9404 - mse: 3.7395\n",
      "Epoch 259/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 222.9389 - mse: 4.8073\n",
      "Epoch 260/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 211.6603 - mse: 3.6992\n",
      "Epoch 261/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 210.7151 - mse: 4.2500\n",
      "Epoch 262/1500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 307.1270 - mse: 10.1418\n",
      "Epoch 263/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 247.3367 - mse: 6.4588\n",
      "Epoch 264/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 273.9983 - mse: 7.8717\n",
      "Epoch 265/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 206.6477 - mse: 3.6643\n",
      "Epoch 266/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 229.2036 - mse: 4.5491\n",
      "Epoch 267/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 277.9657 - mse: 7.9076\n",
      "Epoch 268/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 247.9195 - mse: 5.7232\n",
      "Epoch 269/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 275.1295 - mse: 7.3011\n",
      "Epoch 270/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 242.9821 - mse: 5.9247\n",
      "Epoch 271/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 230.1406 - mse: 4.7055\n",
      "Epoch 272/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 241.8512 - mse: 5.5157\n",
      "Epoch 273/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 216.1016 - mse: 4.1739\n",
      "Epoch 274/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 238.6064 - mse: 6.1867\n",
      "Epoch 275/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 238.5555 - mse: 5.9200\n",
      "Epoch 276/1500\n",
      "32/32 [==============================] - 0s 124us/step - loss: 232.8055 - mse: 4.9381\n",
      "Epoch 277/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 213.6872 - mse: 4.4173\n",
      "Epoch 278/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 244.3236 - mse: 6.2829\n",
      "Epoch 279/1500\n",
      "32/32 [==============================] - 0s 124us/step - loss: 247.0245 - mse: 4.7095\n",
      "Epoch 280/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 246.7524 - mse: 6.2115\n",
      "Epoch 281/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 214.7244 - mse: 3.8720\n",
      "Epoch 282/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 252.3241 - mse: 6.3864\n",
      "Epoch 283/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 215.4417 - mse: 4.1958\n",
      "Epoch 284/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 249.5912 - mse: 6.3472\n",
      "Epoch 285/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 231.2175 - mse: 5.2507\n",
      "Epoch 286/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 213.4440 - mse: 4.0427\n",
      "Epoch 287/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 224.5011 - mse: 4.9116\n",
      "Epoch 288/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 215.4252 - mse: 4.4507\n",
      "Epoch 289/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 211.8419 - mse: 4.9172\n",
      "Epoch 290/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 204.7421 - mse: 3.3945\n",
      "Epoch 291/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 247.2731 - mse: 5.2584\n",
      "Epoch 292/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 203.3148 - mse: 3.9197\n",
      "Epoch 293/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 228.8432 - mse: 4.3828\n",
      "Epoch 294/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 201.7328 - mse: 3.3864\n",
      "Epoch 295/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 211.6693 - mse: 4.0804\n",
      "Epoch 296/1500\n",
      "32/32 [==============================] - 0s 132us/step - loss: 231.0775 - mse: 6.0110\n",
      "Epoch 297/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 235.4457 - mse: 5.0145\n",
      "Epoch 298/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 219.5589 - mse: 4.4185\n",
      "Epoch 299/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 202.8087 - mse: 2.9429\n",
      "Epoch 300/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 210.8883 - mse: 4.0472\n",
      "Epoch 301/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 224.2008 - mse: 3.7813\n",
      "Epoch 302/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 219.2514 - mse: 4.4341\n",
      "Epoch 303/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 209.5347 - mse: 3.5855\n",
      "Epoch 304/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 219.5970 - mse: 4.0601\n",
      "Epoch 305/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 202.1878 - mse: 4.0582\n",
      "Epoch 306/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 215.5722 - mse: 4.4298\n",
      "Epoch 307/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 320.1619 - mse: 10.5965\n",
      "Epoch 308/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 188.5402 - mse: 2.9126\n",
      "Epoch 309/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 201.9690 - mse: 2.6454\n",
      "Epoch 310/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 309.5470 - mse: 9.9892\n",
      "Epoch 311/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 192.5091 - mse: 2.9219\n",
      "Epoch 312/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 215.7729 - mse: 3.7246\n",
      "Epoch 313/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 202.3790 - mse: 3.2841\n",
      "Epoch 314/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 193.0097 - mse: 3.1795\n",
      "Epoch 315/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 212.1364 - mse: 3.9560\n",
      "Epoch 316/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 211.5894 - mse: 4.4541\n",
      "Epoch 317/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 221.2547 - mse: 4.1494\n",
      "Epoch 318/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 206.5223 - mse: 3.4297\n",
      "Epoch 319/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 220.6097 - mse: 3.1162\n",
      "Epoch 320/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 212.3660 - mse: 3.4954\n",
      "Epoch 321/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 459.0192 - mse: 19.6913\n",
      "Epoch 322/1500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 200.8271 - mse: 2.5510\n",
      "Epoch 323/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 207.1391 - mse: 2.9225\n",
      "Epoch 324/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 198.8840 - mse: 3.9472\n",
      "Epoch 325/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 231.7165 - mse: 5.4423\n",
      "Epoch 326/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 270.6754 - mse: 6.3950\n",
      "Epoch 327/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 251.9140 - mse: 6.1900\n",
      "Epoch 328/1500\n",
      "32/32 [==============================] - 0s 124us/step - loss: 229.1550 - mse: 4.5860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 230.5181 - mse: 4.6651\n",
      "Epoch 330/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 224.1542 - mse: 4.3033\n",
      "Epoch 331/1500\n",
      "32/32 [==============================] - 0s 133us/step - loss: 242.5893 - mse: 4.9537\n",
      "Epoch 332/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 204.3225 - mse: 4.0340\n",
      "Epoch 333/1500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 220.0776 - mse: 4.2032\n",
      "Epoch 334/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 192.6132 - mse: 2.4647\n",
      "Epoch 335/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 200.8550 - mse: 3.3563\n",
      "Epoch 336/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 212.7553 - mse: 3.3480\n",
      "Epoch 337/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 226.3381 - mse: 4.8918\n",
      "Epoch 338/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 212.8685 - mse: 4.3085\n",
      "Epoch 339/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 236.8342 - mse: 5.1533\n",
      "Epoch 340/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 190.1346 - mse: 2.5555\n",
      "Epoch 341/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 210.7045 - mse: 3.3781\n",
      "Epoch 342/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 208.6585 - mse: 3.9739\n",
      "Epoch 343/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 214.5646 - mse: 4.1258\n",
      "Epoch 344/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 214.3044 - mse: 4.4713\n",
      "Epoch 345/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 211.1757 - mse: 4.0367\n",
      "Epoch 346/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 243.2361 - mse: 6.9351\n",
      "Epoch 347/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 219.4570 - mse: 4.4110\n",
      "Epoch 348/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 225.6103 - mse: 3.7084\n",
      "Epoch 349/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 204.2663 - mse: 3.2242\n",
      "Epoch 350/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 212.5603 - mse: 4.1170\n",
      "Epoch 351/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 187.0400 - mse: 2.5708\n",
      "Epoch 352/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 203.6697 - mse: 2.9395\n",
      "Epoch 353/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 203.0351 - mse: 2.9916\n",
      "Epoch 354/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 196.9400 - mse: 2.2595\n",
      "Epoch 355/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 202.2935 - mse: 2.5269\n",
      "Epoch 356/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 199.4733 - mse: 2.4396\n",
      "Epoch 357/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 195.4994 - mse: 2.6843\n",
      "Epoch 358/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 212.9149 - mse: 3.7925\n",
      "Epoch 359/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 204.4844 - mse: 3.8422\n",
      "Epoch 360/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 195.3718 - mse: 3.0538\n",
      "Epoch 361/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 253.0975 - mse: 6.3566\n",
      "Epoch 362/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 221.2029 - mse: 4.1047\n",
      "Epoch 363/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 217.3259 - mse: 3.9095\n",
      "Epoch 364/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 187.0415 - mse: 2.7695\n",
      "Epoch 365/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 203.6391 - mse: 2.8059\n",
      "Epoch 366/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 204.2016 - mse: 2.8681\n",
      "Epoch 367/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 284.5646 - mse: 8.5849\n",
      "Epoch 368/1500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 242.9186 - mse: 6.3704\n",
      "Epoch 369/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 282.4429 - mse: 8.9653\n",
      "Epoch 370/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 225.0718 - mse: 4.3942\n",
      "Epoch 371/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 232.8082 - mse: 4.5283\n",
      "Epoch 372/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 193.7720 - mse: 2.4155\n",
      "Epoch 373/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 208.1625 - mse: 3.6992\n",
      "Epoch 374/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 220.1658 - mse: 3.7631\n",
      "Epoch 375/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 205.5325 - mse: 3.5866\n",
      "Epoch 376/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 187.2457 - mse: 2.4941\n",
      "Epoch 377/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 202.7513 - mse: 2.5196\n",
      "Epoch 378/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 194.4585 - mse: 2.7124\n",
      "Epoch 379/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 199.8610 - mse: 2.7167\n",
      "Epoch 380/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 278.5075 - mse: 8.0777\n",
      "Epoch 381/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 195.8245 - mse: 2.4412\n",
      "Epoch 382/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 183.9253 - mse: 2.3551\n",
      "Epoch 383/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 186.2164 - mse: 2.0262\n",
      "Epoch 384/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 194.6328 - mse: 2.4174\n",
      "Epoch 385/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 203.3301 - mse: 2.6327\n",
      "Epoch 386/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 237.5741 - mse: 5.9496\n",
      "Epoch 387/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 221.9819 - mse: 4.3456\n",
      "Epoch 388/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 194.3234 - mse: 2.2106\n",
      "Epoch 389/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 204.1026 - mse: 2.7242\n",
      "Epoch 390/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 200.4648 - mse: 2.3039\n",
      "Epoch 391/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 228.9632 - mse: 5.0563\n",
      "Epoch 392/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 212.0143 - mse: 3.8842\n",
      "Epoch 393/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 234.3062 - mse: 4.7984\n",
      "Epoch 394/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 249.5583 - mse: 5.9135\n",
      "Epoch 395/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 219.8176 - mse: 4.1278\n",
      "Epoch 396/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 206.1525 - mse: 3.0713\n",
      "Epoch 397/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 203.9490 - mse: 2.5235\n",
      "Epoch 398/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 212.0218 - mse: 3.0689\n",
      "Epoch 399/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 218.4798 - mse: 4.5788\n",
      "Epoch 400/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 276.8970 - mse: 7.6307\n",
      "Epoch 401/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 185.8036 - mse: 2.4527\n",
      "Epoch 402/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 194.3866 - mse: 2.5742\n",
      "Epoch 403/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 192.8406 - mse: 2.7726\n",
      "Epoch 404/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 178.8699 - mse: 2.3291\n",
      "Epoch 405/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 203.6090 - mse: 3.4276\n",
      "Epoch 406/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 195.2187 - mse: 3.1054\n",
      "Epoch 407/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 228.5098 - mse: 5.2099\n",
      "Epoch 408/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 196.9543 - mse: 2.4158\n",
      "Epoch 409/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 188.8708 - mse: 2.9550\n",
      "Epoch 410/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 175.0281 - mse: 1.4317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 188.6483 - mse: 2.1452\n",
      "Epoch 412/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 205.4892 - mse: 3.2029\n",
      "Epoch 413/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 222.6480 - mse: 4.5251\n",
      "Epoch 414/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 232.8935 - mse: 4.5453\n",
      "Epoch 415/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 190.4257 - mse: 2.6160\n",
      "Epoch 416/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 203.3153 - mse: 3.0187\n",
      "Epoch 417/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 205.7990 - mse: 3.2570\n",
      "Epoch 418/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 220.6163 - mse: 3.3268\n",
      "Epoch 419/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 264.7701 - mse: 7.6953\n",
      "Epoch 420/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 188.7877 - mse: 2.2116\n",
      "Epoch 421/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 188.4012 - mse: 2.0242\n",
      "Epoch 422/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 212.7997 - mse: 3.7927\n",
      "Epoch 423/1500\n",
      "32/32 [==============================] - 0s 129us/step - loss: 171.2438 - mse: 1.9210\n",
      "Epoch 424/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 252.7287 - mse: 6.3618\n",
      "Epoch 425/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 196.5494 - mse: 2.8436\n",
      "Epoch 426/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 370.5880 - mse: 14.4147\n",
      "Epoch 427/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 198.7975 - mse: 3.4698\n",
      "Epoch 428/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 198.5512 - mse: 2.6720\n",
      "Epoch 429/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 180.0746 - mse: 2.1097\n",
      "Epoch 430/1500\n",
      "32/32 [==============================] - 0s 151us/step - loss: 233.1003 - mse: 5.0186\n",
      "Epoch 431/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 187.5007 - mse: 2.3055\n",
      "Epoch 432/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 240.4162 - mse: 6.2001\n",
      "Epoch 433/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 237.1907 - mse: 5.7152\n",
      "Epoch 434/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 192.7153 - mse: 2.1062\n",
      "Epoch 435/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 238.6887 - mse: 5.0762\n",
      "Epoch 436/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 266.5757 - mse: 8.2933\n",
      "Epoch 437/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 191.4654 - mse: 2.1363\n",
      "Epoch 438/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 197.7551 - mse: 2.8554\n",
      "Epoch 439/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 200.2531 - mse: 3.0178\n",
      "Epoch 440/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 210.3951 - mse: 3.6335\n",
      "Epoch 441/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 202.6823 - mse: 2.5219\n",
      "Epoch 442/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 231.0055 - mse: 5.2798\n",
      "Epoch 443/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 202.1307 - mse: 3.2410\n",
      "Epoch 444/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 203.4373 - mse: 2.2645\n",
      "Epoch 445/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 185.5087 - mse: 2.1062\n",
      "Epoch 446/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 203.7439 - mse: 2.7263\n",
      "Epoch 447/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 200.7945 - mse: 3.1405\n",
      "Epoch 448/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 191.1178 - mse: 1.8490\n",
      "Epoch 449/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 213.7361 - mse: 3.6005\n",
      "Epoch 450/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 185.2159 - mse: 1.5232\n",
      "Epoch 451/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 210.6536 - mse: 2.3803\n",
      "Epoch 452/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 191.0337 - mse: 1.7534\n",
      "Epoch 453/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 201.2172 - mse: 3.7196\n",
      "Epoch 454/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 213.2981 - mse: 3.4109\n",
      "Epoch 455/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 186.9902 - mse: 1.9997\n",
      "Epoch 456/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 192.4337 - mse: 2.4923\n",
      "Epoch 457/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 203.0398 - mse: 2.8833\n",
      "Epoch 458/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 213.8128 - mse: 2.8706\n",
      "Epoch 459/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 238.3339 - mse: 4.3894\n",
      "Epoch 460/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 196.3550 - mse: 2.0560\n",
      "Epoch 461/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 208.3781 - mse: 1.8775\n",
      "Epoch 462/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 193.0887 - mse: 1.9103\n",
      "Epoch 463/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 218.5527 - mse: 3.7020\n",
      "Epoch 464/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 246.7677 - mse: 5.5594\n",
      "Epoch 465/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 213.8805 - mse: 4.3298\n",
      "Epoch 466/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 200.8437 - mse: 2.5201\n",
      "Epoch 467/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 196.8235 - mse: 1.6244\n",
      "Epoch 468/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 176.4467 - mse: 1.8312\n",
      "Epoch 469/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 184.6484 - mse: 1.4248\n",
      "Epoch 470/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 192.5366 - mse: 1.4807\n",
      "Epoch 471/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 199.5601 - mse: 2.3914\n",
      "Epoch 472/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 197.8471 - mse: 2.1408\n",
      "Epoch 473/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 202.5707 - mse: 2.2385\n",
      "Epoch 474/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 185.6043 - mse: 1.6017\n",
      "Epoch 475/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 303.6410 - mse: 9.1505\n",
      "Epoch 476/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 200.2156 - mse: 3.0820\n",
      "Epoch 477/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 192.0878 - mse: 2.3245\n",
      "Epoch 478/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 190.6432 - mse: 2.7498\n",
      "Epoch 479/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 210.8864 - mse: 3.4898\n",
      "Epoch 480/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 193.1878 - mse: 2.1396\n",
      "Epoch 481/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 196.2859 - mse: 2.4782\n",
      "Epoch 482/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 192.5573 - mse: 2.3631\n",
      "Epoch 483/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 214.4148 - mse: 2.8659\n",
      "Epoch 484/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 219.4608 - mse: 3.1277\n",
      "Epoch 485/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 186.1202 - mse: 1.5884\n",
      "Epoch 486/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 198.4490 - mse: 2.5835\n",
      "Epoch 487/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 204.5888 - mse: 2.8383\n",
      "Epoch 488/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 201.8428 - mse: 2.6044\n",
      "Epoch 489/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 190.9904 - mse: 1.7980\n",
      "Epoch 490/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 221.5993 - mse: 3.8870\n",
      "Epoch 491/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 181.2610 - mse: 1.4042\n",
      "Epoch 492/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 189.0161 - mse: 1.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 213.6003 - mse: 2.9366\n",
      "Epoch 494/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 207.6973 - mse: 2.0811\n",
      "Epoch 495/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 188.6145 - mse: 1.5787\n",
      "Epoch 496/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 201.8262 - mse: 1.8152\n",
      "Epoch 497/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 192.8305 - mse: 2.1028\n",
      "Epoch 498/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 200.5885 - mse: 1.8289\n",
      "Epoch 499/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 201.2278 - mse: 2.0174\n",
      "Epoch 500/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 200.2340 - mse: 1.5373\n",
      "Epoch 501/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 208.4461 - mse: 3.4197\n",
      "Epoch 502/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 204.4643 - mse: 3.0006\n",
      "Epoch 503/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 228.2102 - mse: 4.3482\n",
      "Epoch 504/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 193.8279 - mse: 1.8307\n",
      "Epoch 505/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 201.6497 - mse: 1.7313\n",
      "Epoch 506/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 189.9195 - mse: 1.9234\n",
      "Epoch 507/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 220.2075 - mse: 4.7557\n",
      "Epoch 508/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 203.1732 - mse: 3.2288\n",
      "Epoch 509/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 196.8837 - mse: 2.1973\n",
      "Epoch 510/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 229.3115 - mse: 5.1278\n",
      "Epoch 511/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 186.4101 - mse: 1.1442\n",
      "Epoch 512/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 208.4121 - mse: 2.3679\n",
      "Epoch 513/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 195.1085 - mse: 2.2908\n",
      "Epoch 514/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 200.0394 - mse: 2.9382\n",
      "Epoch 515/1500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 213.7262 - mse: 3.2464\n",
      "Epoch 516/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 191.3935 - mse: 2.4859\n",
      "Epoch 517/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 182.2971 - mse: 1.8364\n",
      "Epoch 518/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 212.9852 - mse: 3.1477\n",
      "Epoch 519/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 207.9660 - mse: 2.8578\n",
      "Epoch 520/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 177.6105 - mse: 1.1117\n",
      "Epoch 521/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 192.4230 - mse: 1.9643\n",
      "Epoch 522/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 190.4278 - mse: 2.1183\n",
      "Epoch 523/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 201.3268 - mse: 2.5829\n",
      "Epoch 524/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 196.6979 - mse: 2.3351\n",
      "Epoch 525/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 210.8510 - mse: 2.8920\n",
      "Epoch 526/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 204.9739 - mse: 3.0707\n",
      "Epoch 527/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 186.7304 - mse: 1.6328\n",
      "Epoch 528/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 179.2890 - mse: 1.9092\n",
      "Epoch 529/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 217.7083 - mse: 3.5288\n",
      "Epoch 530/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 200.5585 - mse: 2.9031\n",
      "Epoch 531/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 179.7101 - mse: 1.4818\n",
      "Epoch 532/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 201.8904 - mse: 2.8720\n",
      "Epoch 533/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 195.4565 - mse: 2.8775\n",
      "Epoch 534/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 172.7739 - mse: 1.6399\n",
      "Epoch 535/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 200.7319 - mse: 2.5183\n",
      "Epoch 536/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 214.4289 - mse: 3.6670\n",
      "Epoch 537/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 236.1981 - mse: 4.4730\n",
      "Epoch 538/1500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 196.1096 - mse: 2.0243\n",
      "Epoch 539/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 201.5004 - mse: 2.8446\n",
      "Epoch 540/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 186.4604 - mse: 1.7430\n",
      "Epoch 541/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 205.0773 - mse: 2.4542\n",
      "Epoch 542/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 191.4587 - mse: 1.9457\n",
      "Epoch 543/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 176.4745 - mse: 1.5732\n",
      "Epoch 544/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 184.2554 - mse: 1.2212\n",
      "Epoch 545/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 196.0678 - mse: 2.4242\n",
      "Epoch 546/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 204.5266 - mse: 2.7560\n",
      "Epoch 547/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 191.9905 - mse: 2.1928\n",
      "Epoch 548/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 223.7354 - mse: 4.0405\n",
      "Epoch 549/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 246.0454 - mse: 4.8315\n",
      "Epoch 550/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 231.5175 - mse: 4.5270\n",
      "Epoch 551/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 177.3252 - mse: 1.3839\n",
      "Epoch 552/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 169.2656 - mse: 1.5006\n",
      "Epoch 553/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 195.2122 - mse: 1.9922\n",
      "Epoch 554/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 208.1357 - mse: 2.9789\n",
      "Epoch 555/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 183.1167 - mse: 2.1417\n",
      "Epoch 556/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 214.4900 - mse: 3.9338\n",
      "Epoch 557/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 263.4179 - mse: 6.4900\n",
      "Epoch 558/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 188.2876 - mse: 1.8697\n",
      "Epoch 559/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 183.9103 - mse: 1.5870\n",
      "Epoch 560/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 180.3466 - mse: 1.4914\n",
      "Epoch 561/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 185.6935 - mse: 2.2911\n",
      "Epoch 562/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 191.9564 - mse: 1.9326\n",
      "Epoch 563/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 224.2464 - mse: 4.1863\n",
      "Epoch 564/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 194.9462 - mse: 1.9810\n",
      "Epoch 565/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 225.4437 - mse: 4.8712\n",
      "Epoch 566/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 242.9782 - mse: 5.9877\n",
      "Epoch 567/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 178.7926 - mse: 1.7241\n",
      "Epoch 568/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 183.9895 - mse: 1.5759\n",
      "Epoch 569/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 183.8505 - mse: 1.6024\n",
      "Epoch 570/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 185.9333 - mse: 1.4950\n",
      "Epoch 571/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 190.5716 - mse: 1.8051\n",
      "Epoch 572/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 194.9948 - mse: 2.7154\n",
      "Epoch 573/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 181.5988 - mse: 1.9765\n",
      "Epoch 574/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 183.6802 - mse: 2.3449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 183.5223 - mse: 1.8016\n",
      "Epoch 576/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 193.6030 - mse: 2.0096\n",
      "Epoch 577/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 209.6295 - mse: 2.4969\n",
      "Epoch 578/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 174.0375 - mse: 1.5491\n",
      "Epoch 579/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 177.3770 - mse: 1.2707\n",
      "Epoch 580/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 182.5863 - mse: 2.9111\n",
      "Epoch 581/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 197.0357 - mse: 2.2916\n",
      "Epoch 582/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 189.9863 - mse: 3.1832\n",
      "Epoch 583/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 174.7728 - mse: 1.1616\n",
      "Epoch 584/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 182.4344 - mse: 1.4421\n",
      "Epoch 585/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 203.2560 - mse: 2.3587\n",
      "Epoch 586/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 202.9808 - mse: 2.0976\n",
      "Epoch 587/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 186.5732 - mse: 1.2151\n",
      "Epoch 588/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 193.8770 - mse: 1.4624\n",
      "Epoch 589/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 183.7813 - mse: 2.1968\n",
      "Epoch 590/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 308.1833 - mse: 10.8120\n",
      "Epoch 591/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 208.2364 - mse: 2.5034\n",
      "Epoch 592/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 187.9639 - mse: 1.6220\n",
      "Epoch 593/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 197.6140 - mse: 1.5695\n",
      "Epoch 594/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 195.1192 - mse: 2.3315\n",
      "Epoch 595/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 193.9885 - mse: 1.8109\n",
      "Epoch 596/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 314.0265 - mse: 9.3747\n",
      "Epoch 597/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 207.7682 - mse: 2.8520\n",
      "Epoch 598/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 200.2877 - mse: 2.1695\n",
      "Epoch 599/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 173.5886 - mse: 1.1012\n",
      "Epoch 600/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 185.7401 - mse: 1.6060\n",
      "Epoch 601/1500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 192.3343 - mse: 1.7631\n",
      "Epoch 602/1500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 205.4409 - mse: 3.3239\n",
      "Epoch 603/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 172.4176 - mse: 1.4639\n",
      "Epoch 604/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 176.7086 - mse: 1.3696\n",
      "Epoch 605/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 184.3589 - mse: 1.9972\n",
      "Epoch 606/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 166.9672 - mse: 1.1835\n",
      "Epoch 607/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 183.5561 - mse: 1.2854\n",
      "Epoch 608/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 215.9515 - mse: 3.1946\n",
      "Epoch 609/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 185.2820 - mse: 2.4008\n",
      "Epoch 610/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 187.9703 - mse: 1.2754\n",
      "Epoch 611/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 184.9551 - mse: 1.3469\n",
      "Epoch 612/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 183.2158 - mse: 1.5089\n",
      "Epoch 613/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 178.1456 - mse: 1.3051\n",
      "Epoch 614/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 196.8375 - mse: 2.3534\n",
      "Epoch 615/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 192.0667 - mse: 2.4805\n",
      "Epoch 616/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 184.5243 - mse: 1.1899\n",
      "Epoch 617/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 198.6197 - mse: 2.1693\n",
      "Epoch 618/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 280.4575 - mse: 7.6722\n",
      "Epoch 619/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 216.6272 - mse: 2.8950\n",
      "Epoch 620/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 191.0109 - mse: 2.2379\n",
      "Epoch 621/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 190.7290 - mse: 1.3158\n",
      "Epoch 622/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 173.7819 - mse: 1.4796\n",
      "Epoch 623/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 199.1728 - mse: 2.9034\n",
      "Epoch 624/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 182.6234 - mse: 1.2611\n",
      "Epoch 625/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 238.7672 - mse: 4.0460\n",
      "Epoch 626/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 201.3392 - mse: 2.9106\n",
      "Epoch 627/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 200.9969 - mse: 2.6477\n",
      "Epoch 628/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 190.9899 - mse: 2.0332\n",
      "Epoch 629/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 183.5770 - mse: 1.3259\n",
      "Epoch 630/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 213.6441 - mse: 3.0468\n",
      "Epoch 631/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 219.1245 - mse: 2.8001\n",
      "Epoch 632/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 188.7886 - mse: 2.5227\n",
      "Epoch 633/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 177.4237 - mse: 2.3385\n",
      "Epoch 634/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 169.2135 - mse: 1.0701\n",
      "Epoch 635/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 212.1110 - mse: 3.8110\n",
      "Epoch 636/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 189.0230 - mse: 1.5547\n",
      "Epoch 637/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 185.0376 - mse: 1.2067\n",
      "Epoch 638/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 209.6765 - mse: 2.9912\n",
      "Epoch 639/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 182.3625 - mse: 1.1475\n",
      "Epoch 640/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 185.0227 - mse: 1.9328\n",
      "Epoch 641/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 177.1305 - mse: 1.3158\n",
      "Epoch 642/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 199.7625 - mse: 2.0771\n",
      "Epoch 643/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 181.4324 - mse: 1.7898\n",
      "Epoch 644/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 187.4828 - mse: 2.7498\n",
      "Epoch 645/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 185.3308 - mse: 1.2048\n",
      "Epoch 646/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 187.0614 - mse: 1.9642\n",
      "Epoch 647/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 204.0430 - mse: 3.3751\n",
      "Epoch 648/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 171.0375 - mse: 1.2840\n",
      "Epoch 649/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 193.2002 - mse: 1.9913\n",
      "Epoch 650/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 196.6472 - mse: 1.7561\n",
      "Epoch 651/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 184.1830 - mse: 1.8093\n",
      "Epoch 652/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 184.4037 - mse: 1.2016\n",
      "Epoch 653/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 187.8590 - mse: 1.0034\n",
      "Epoch 654/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 209.9587 - mse: 2.3740\n",
      "Epoch 655/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 184.3619 - mse: 1.4746\n",
      "Epoch 656/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 179.3628 - mse: 1.4443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 207.4363 - mse: 3.0963\n",
      "Epoch 658/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 182.6759 - mse: 1.3621\n",
      "Epoch 659/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 169.8703 - mse: 1.3529\n",
      "Epoch 660/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 191.0011 - mse: 1.3184\n",
      "Epoch 661/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 186.9834 - mse: 2.0591\n",
      "Epoch 662/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 168.8457 - mse: 0.8915\n",
      "Epoch 663/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 182.9199 - mse: 1.3237\n",
      "Epoch 664/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 181.8983 - mse: 1.5768\n",
      "Epoch 665/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 190.3121 - mse: 1.9274\n",
      "Epoch 666/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 174.4691 - mse: 1.3227\n",
      "Epoch 667/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 192.4239 - mse: 1.6944\n",
      "Epoch 668/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 188.9484 - mse: 2.2693\n",
      "Epoch 669/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 190.7059 - mse: 2.1350\n",
      "Epoch 670/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 197.0369 - mse: 2.6072\n",
      "Epoch 671/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 188.1411 - mse: 2.0735\n",
      "Epoch 672/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 178.5238 - mse: 1.2185\n",
      "Epoch 673/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 185.9087 - mse: 2.2446\n",
      "Epoch 674/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 253.8858 - mse: 6.3582\n",
      "Epoch 675/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 175.4648 - mse: 1.9036\n",
      "Epoch 676/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 185.6333 - mse: 1.7790\n",
      "Epoch 677/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 195.5626 - mse: 1.8647\n",
      "Epoch 678/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 191.5757 - mse: 1.5128\n",
      "Epoch 679/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 187.7820 - mse: 1.8933\n",
      "Epoch 680/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 212.3539 - mse: 2.9473\n",
      "Epoch 681/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 194.9550 - mse: 2.4251\n",
      "Epoch 682/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 183.9044 - mse: 1.3887\n",
      "Epoch 683/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 166.6154 - mse: 1.1447\n",
      "Epoch 684/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 186.3643 - mse: 1.7960\n",
      "Epoch 685/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 188.6089 - mse: 1.9062\n",
      "Epoch 686/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 171.9742 - mse: 1.1558\n",
      "Epoch 687/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 186.3061 - mse: 1.2204\n",
      "Epoch 688/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 172.4779 - mse: 1.5410\n",
      "Epoch 689/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 172.9966 - mse: 1.2766\n",
      "Epoch 690/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 173.2280 - mse: 1.3610\n",
      "Epoch 691/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 251.4263 - mse: 5.7236\n",
      "Epoch 692/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 182.3165 - mse: 2.0492\n",
      "Epoch 693/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 178.0349 - mse: 1.2164\n",
      "Epoch 694/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 186.0490 - mse: 2.3708\n",
      "Epoch 695/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 196.9933 - mse: 2.4817\n",
      "Epoch 696/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 184.7113 - mse: 1.2782\n",
      "Epoch 697/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 204.7435 - mse: 2.4470\n",
      "Epoch 698/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 177.2836 - mse: 1.7751\n",
      "Epoch 699/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 199.9266 - mse: 2.8507\n",
      "Epoch 700/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 250.9082 - mse: 6.6575\n",
      "Epoch 701/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 174.4657 - mse: 1.4461\n",
      "Epoch 702/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 182.1624 - mse: 1.3315\n",
      "Epoch 703/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 214.4876 - mse: 3.4126\n",
      "Epoch 704/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 174.2481 - mse: 1.8267\n",
      "Epoch 705/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 171.3488 - mse: 1.4190\n",
      "Epoch 706/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 199.2440 - mse: 2.5155\n",
      "Epoch 707/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 176.4694 - mse: 1.7780\n",
      "Epoch 708/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 195.7860 - mse: 2.0903\n",
      "Epoch 709/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 185.9178 - mse: 2.3247\n",
      "Epoch 710/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 184.1167 - mse: 1.8466\n",
      "Epoch 711/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 179.4478 - mse: 1.9818\n",
      "Epoch 712/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 207.4575 - mse: 3.3244\n",
      "Epoch 713/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 218.0833 - mse: 3.5160\n",
      "Epoch 714/1500\n",
      "32/32 [==============================] - 0s 130us/step - loss: 196.9438 - mse: 3.6800\n",
      "Epoch 715/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 187.2865 - mse: 1.6438\n",
      "Epoch 716/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 174.0938 - mse: 1.2780\n",
      "Epoch 717/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 180.0491 - mse: 1.4586\n",
      "Epoch 718/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 211.0569 - mse: 3.4349\n",
      "Epoch 719/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 183.7138 - mse: 1.4318\n",
      "Epoch 720/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 202.3174 - mse: 3.3200\n",
      "Epoch 721/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 182.5052 - mse: 1.0617\n",
      "Epoch 722/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 198.4882 - mse: 2.4907\n",
      "Epoch 723/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 186.6059 - mse: 2.1341\n",
      "Epoch 724/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 179.1987 - mse: 1.6550\n",
      "Epoch 725/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 171.0659 - mse: 1.4504\n",
      "Epoch 726/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 176.8495 - mse: 1.2826\n",
      "Epoch 727/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 188.9112 - mse: 1.5897\n",
      "Epoch 728/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 180.4652 - mse: 2.4472\n",
      "Epoch 729/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 193.2265 - mse: 2.2825\n",
      "Epoch 730/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 205.2189 - mse: 3.2047\n",
      "Epoch 731/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 183.2689 - mse: 1.4963\n",
      "Epoch 732/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 197.7599 - mse: 2.4968\n",
      "Epoch 733/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 186.7856 - mse: 1.8243\n",
      "Epoch 734/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 198.5036 - mse: 3.4616\n",
      "Epoch 735/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 197.6916 - mse: 2.4113\n",
      "Epoch 736/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 181.0388 - mse: 1.8752\n",
      "Epoch 737/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 185.3646 - mse: 1.2676\n",
      "Epoch 738/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 199.9682 - mse: 2.4947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 169.7275 - mse: 1.1397\n",
      "Epoch 740/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 183.6620 - mse: 1.9676\n",
      "Epoch 741/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 177.0483 - mse: 1.0256\n",
      "Epoch 742/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 203.6225 - mse: 3.1797\n",
      "Epoch 743/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 180.0872 - mse: 1.9272\n",
      "Epoch 744/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 192.9394 - mse: 2.0916\n",
      "Epoch 745/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 184.6287 - mse: 1.9977\n",
      "Epoch 746/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 191.8541 - mse: 2.3253\n",
      "Epoch 747/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 188.9672 - mse: 1.9545\n",
      "Epoch 748/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 171.2460 - mse: 1.4959\n",
      "Epoch 749/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 172.0154 - mse: 1.5463\n",
      "Epoch 750/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 174.1786 - mse: 1.7077\n",
      "Epoch 751/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 181.4656 - mse: 1.6910\n",
      "Epoch 752/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 216.3954 - mse: 4.0364\n",
      "Epoch 753/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 252.2572 - mse: 6.4078\n",
      "Epoch 754/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 230.4581 - mse: 4.2166\n",
      "Epoch 755/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 180.2283 - mse: 1.4343\n",
      "Epoch 756/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 177.7529 - mse: 1.0354\n",
      "Epoch 757/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 192.8515 - mse: 2.5072\n",
      "Epoch 758/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 242.5648 - mse: 5.8387\n",
      "Epoch 759/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 270.8087 - mse: 6.8686\n",
      "Epoch 760/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 218.0733 - mse: 4.4911\n",
      "Epoch 761/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 198.4781 - mse: 2.9869\n",
      "Epoch 762/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 165.3056 - mse: 1.0907\n",
      "Epoch 763/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 181.0556 - mse: 1.7493\n",
      "Epoch 764/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 178.0958 - mse: 1.8811\n",
      "Epoch 765/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 184.8335 - mse: 1.7737\n",
      "Epoch 766/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 213.9467 - mse: 3.9292\n",
      "Epoch 767/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 197.5272 - mse: 3.0758\n",
      "Epoch 768/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 193.2802 - mse: 2.6028\n",
      "Epoch 769/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 255.9234 - mse: 6.2127\n",
      "Epoch 770/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 186.8430 - mse: 1.9726\n",
      "Epoch 771/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 171.8224 - mse: 1.1867\n",
      "Epoch 772/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 197.4342 - mse: 3.3819\n",
      "Epoch 773/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 263.7725 - mse: 7.0066\n",
      "Epoch 774/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 187.5244 - mse: 1.7298\n",
      "Epoch 775/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 198.1200 - mse: 2.4781\n",
      "Epoch 776/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 177.2697 - mse: 1.6466\n",
      "Epoch 777/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 199.8661 - mse: 2.6563\n",
      "Epoch 778/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 193.3227 - mse: 2.6977\n",
      "Epoch 779/1500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 194.9048 - mse: 2.1179\n",
      "Epoch 780/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 188.8795 - mse: 2.1261\n",
      "Epoch 781/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 169.3272 - mse: 1.2933\n",
      "Epoch 782/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 189.7380 - mse: 1.5552\n",
      "Epoch 783/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 216.9644 - mse: 4.4623\n",
      "Epoch 784/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 210.8306 - mse: 2.2693\n",
      "Epoch 785/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 182.1551 - mse: 1.2984\n",
      "Epoch 786/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 198.2358 - mse: 2.3038\n",
      "Epoch 787/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 171.0790 - mse: 1.2782\n",
      "Epoch 788/1500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 200.2343 - mse: 3.1138\n",
      "Epoch 789/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 188.6482 - mse: 1.8269\n",
      "Epoch 790/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 196.8394 - mse: 2.2000\n",
      "Epoch 791/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 181.8318 - mse: 1.7630\n",
      "Epoch 792/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 179.7419 - mse: 1.4209\n",
      "Epoch 793/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 180.6696 - mse: 2.0649\n",
      "Epoch 794/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 187.9898 - mse: 1.5236\n",
      "Epoch 795/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 199.9839 - mse: 2.8087\n",
      "Epoch 796/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 179.8355 - mse: 1.3138\n",
      "Epoch 797/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 187.8554 - mse: 1.6977\n",
      "Epoch 798/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 191.2565 - mse: 1.6684\n",
      "Epoch 799/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 173.0433 - mse: 1.2725\n",
      "Epoch 800/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 187.3772 - mse: 2.0311\n",
      "Epoch 801/1500\n",
      "32/32 [==============================] - 0s 131us/step - loss: 176.3332 - mse: 1.6849\n",
      "Epoch 802/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 209.4239 - mse: 2.9521\n",
      "Epoch 803/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 201.7298 - mse: 2.5998\n",
      "Epoch 804/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 211.5143 - mse: 3.8698\n",
      "Epoch 805/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 217.4369 - mse: 4.6696\n",
      "Epoch 806/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 272.9793 - mse: 7.9770\n",
      "Epoch 807/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 192.5964 - mse: 3.2511\n",
      "Epoch 808/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 189.7653 - mse: 2.2365\n",
      "Epoch 809/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 176.5689 - mse: 1.7230\n",
      "Epoch 810/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 198.1547 - mse: 2.3301\n",
      "Epoch 811/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 198.9858 - mse: 3.8087\n",
      "Epoch 812/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 194.7758 - mse: 3.0048\n",
      "Epoch 813/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 174.6414 - mse: 1.3386\n",
      "Epoch 814/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 192.1325 - mse: 2.4439\n",
      "Epoch 815/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 190.0968 - mse: 2.0988\n",
      "Epoch 816/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 179.2457 - mse: 1.3857\n",
      "Epoch 817/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 177.7397 - mse: 1.3357\n",
      "Epoch 818/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 184.7680 - mse: 1.9431\n",
      "Epoch 819/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 208.9657 - mse: 3.2558\n",
      "Epoch 820/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 177.9849 - mse: 1.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 183.2343 - mse: 1.4508\n",
      "Epoch 822/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 184.9061 - mse: 1.1656\n",
      "Epoch 823/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 191.1785 - mse: 2.0991\n",
      "Epoch 824/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 183.2901 - mse: 1.5915\n",
      "Epoch 825/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 173.8281 - mse: 1.8852\n",
      "Epoch 826/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 187.8524 - mse: 2.7258\n",
      "Epoch 827/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 192.3260 - mse: 2.3255\n",
      "Epoch 828/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 495.5750 - mse: 20.5311\n",
      "Epoch 829/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 180.0780 - mse: 1.6151\n",
      "Epoch 830/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 174.7968 - mse: 1.4910\n",
      "Epoch 831/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 211.7325 - mse: 4.4079\n",
      "Epoch 832/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 183.7708 - mse: 1.7665\n",
      "Epoch 833/1500\n",
      "32/32 [==============================] - 0s 195us/step - loss: 203.6576 - mse: 2.7427\n",
      "Epoch 834/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 181.0864 - mse: 1.3500\n",
      "Epoch 835/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 172.8372 - mse: 1.0244\n",
      "Epoch 836/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 195.9158 - mse: 2.9485\n",
      "Epoch 837/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 209.7150 - mse: 4.1938\n",
      "Epoch 838/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 175.8351 - mse: 1.2549\n",
      "Epoch 839/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 202.1842 - mse: 2.4116\n",
      "Epoch 840/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 188.6039 - mse: 1.9642\n",
      "Epoch 841/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 252.9682 - mse: 5.7590\n",
      "Epoch 842/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 207.3326 - mse: 2.0451\n",
      "Epoch 843/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 191.7053 - mse: 2.2631\n",
      "Epoch 844/1500\n",
      "32/32 [==============================] - 0s 142us/step - loss: 198.1017 - mse: 2.0017\n",
      "Epoch 845/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 230.3969 - mse: 5.1868\n",
      "Epoch 846/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 208.8348 - mse: 1.7358\n",
      "Epoch 847/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 189.5756 - mse: 2.0005\n",
      "Epoch 848/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 198.5408 - mse: 1.8426\n",
      "Epoch 849/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 200.9303 - mse: 3.1453\n",
      "Epoch 850/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 225.9928 - mse: 3.6337\n",
      "Epoch 851/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 193.0045 - mse: 1.6344\n",
      "Epoch 852/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 181.4593 - mse: 1.7373\n",
      "Epoch 853/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 209.2584 - mse: 3.7947\n",
      "Epoch 854/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 187.4248 - mse: 2.2399\n",
      "Epoch 855/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 192.9612 - mse: 2.0068\n",
      "Epoch 856/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 185.5085 - mse: 1.4580\n",
      "Epoch 857/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 170.4096 - mse: 1.4218\n",
      "Epoch 858/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 179.0024 - mse: 1.4204\n",
      "Epoch 859/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 384.9924 - mse: 14.7583\n",
      "Epoch 860/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 181.6402 - mse: 1.4211\n",
      "Epoch 861/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 176.3571 - mse: 1.2873\n",
      "Epoch 862/1500\n",
      "32/32 [==============================] - 0s 124us/step - loss: 206.7458 - mse: 3.0748\n",
      "Epoch 863/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 196.2806 - mse: 1.6916\n",
      "Epoch 864/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 177.9092 - mse: 1.7947\n",
      "Epoch 865/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 173.6982 - mse: 1.6687\n",
      "Epoch 866/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 169.7753 - mse: 1.1031\n",
      "Epoch 867/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 184.1055 - mse: 0.9770\n",
      "Epoch 868/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 211.7802 - mse: 2.8669\n",
      "Epoch 869/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 237.5075 - mse: 4.5474\n",
      "Epoch 870/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 182.5710 - mse: 0.8889\n",
      "Epoch 871/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 180.7076 - mse: 2.4583\n",
      "Epoch 872/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 184.5116 - mse: 1.0076\n",
      "Epoch 873/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 199.1293 - mse: 2.7546\n",
      "Epoch 874/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 197.9767 - mse: 1.6084\n",
      "Epoch 875/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 194.7213 - mse: 1.3455\n",
      "Epoch 876/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 193.8559 - mse: 1.8549\n",
      "Epoch 877/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 204.4297 - mse: 1.8407\n",
      "Epoch 878/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 180.0220 - mse: 0.9685\n",
      "Epoch 879/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 178.4229 - mse: 1.2785\n",
      "Epoch 880/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 204.1788 - mse: 2.4287\n",
      "Epoch 881/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 188.7504 - mse: 1.8116\n",
      "Epoch 882/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 159.5495 - mse: 1.0285\n",
      "Epoch 883/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 176.2542 - mse: 1.1950\n",
      "Epoch 884/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 190.1421 - mse: 1.7533\n",
      "Epoch 885/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 204.2290 - mse: 2.8271\n",
      "Epoch 886/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 180.5641 - mse: 1.4422\n",
      "Epoch 887/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 194.0580 - mse: 2.1686\n",
      "Epoch 888/1500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 218.0667 - mse: 4.0719\n",
      "Epoch 889/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 173.7580 - mse: 1.4815\n",
      "Epoch 890/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 188.3007 - mse: 1.4394\n",
      "Epoch 891/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 177.2648 - mse: 1.3049\n",
      "Epoch 892/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 187.2132 - mse: 1.2903\n",
      "Epoch 893/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 198.6210 - mse: 1.4510\n",
      "Epoch 894/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 187.4268 - mse: 1.8174\n",
      "Epoch 895/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 169.9402 - mse: 1.3440\n",
      "Epoch 896/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 187.5556 - mse: 2.1247\n",
      "Epoch 897/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 182.7660 - mse: 1.3903\n",
      "Epoch 898/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 169.8606 - mse: 1.2444\n",
      "Epoch 899/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 187.7547 - mse: 1.3210\n",
      "Epoch 900/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 193.0468 - mse: 1.4613\n",
      "Epoch 901/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 208.3348 - mse: 4.2347\n",
      "Epoch 902/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 176.3174 - mse: 1.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 903/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 182.8802 - mse: 2.1042\n",
      "Epoch 904/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 190.8396 - mse: 1.6243\n",
      "Epoch 905/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 192.2968 - mse: 1.5604\n",
      "Epoch 906/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 203.6231 - mse: 3.4120\n",
      "Epoch 907/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 211.2549 - mse: 3.3155\n",
      "Epoch 908/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 189.5214 - mse: 1.9123\n",
      "Epoch 909/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 189.4118 - mse: 2.2207\n",
      "Epoch 910/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 203.9785 - mse: 2.9202\n",
      "Epoch 911/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 195.0110 - mse: 1.7126\n",
      "Epoch 912/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 201.5555 - mse: 2.9958\n",
      "Epoch 913/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 197.0049 - mse: 2.6513\n",
      "Epoch 914/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 199.6473 - mse: 3.3540\n",
      "Epoch 915/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 187.8179 - mse: 2.1008\n",
      "Epoch 916/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 188.6412 - mse: 2.1219\n",
      "Epoch 917/1500\n",
      "32/32 [==============================] - 0s 131us/step - loss: 183.6306 - mse: 1.3773\n",
      "Epoch 918/1500\n",
      "32/32 [==============================] - 0s 129us/step - loss: 169.5922 - mse: 1.0473\n",
      "Epoch 919/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 168.0385 - mse: 0.9558\n",
      "Epoch 920/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 188.3169 - mse: 1.3541\n",
      "Epoch 921/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 179.9134 - mse: 1.2307\n",
      "Epoch 922/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 195.3210 - mse: 2.1012\n",
      "Epoch 923/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 200.3600 - mse: 2.5173\n",
      "Epoch 924/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 188.5648 - mse: 2.6133\n",
      "Epoch 925/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 190.5680 - mse: 1.6236\n",
      "Epoch 926/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 196.6672 - mse: 2.7783\n",
      "Epoch 927/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 188.2282 - mse: 1.4004\n",
      "Epoch 928/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 183.8526 - mse: 1.4212\n",
      "Epoch 929/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 180.4459 - mse: 1.0169\n",
      "Epoch 930/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 196.7309 - mse: 2.7525\n",
      "Epoch 931/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 181.5216 - mse: 2.1156\n",
      "Epoch 932/1500\n",
      "32/32 [==============================] - 0s 135us/step - loss: 179.6388 - mse: 1.6114\n",
      "Epoch 933/1500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 189.5355 - mse: 1.8943\n",
      "Epoch 934/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 184.4212 - mse: 1.8690\n",
      "Epoch 935/1500\n",
      "32/32 [==============================] - 0s 155us/step - loss: 180.8975 - mse: 1.7816\n",
      "Epoch 936/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 176.3484 - mse: 1.3408\n",
      "Epoch 937/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 187.4386 - mse: 1.5348\n",
      "Epoch 938/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 198.1695 - mse: 2.2357\n",
      "Epoch 939/1500\n",
      "32/32 [==============================] - 0s 120us/step - loss: 175.7036 - mse: 1.3560\n",
      "Epoch 940/1500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 186.9885 - mse: 1.2720\n",
      "Epoch 941/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 175.1368 - mse: 1.5918\n",
      "Epoch 942/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 186.9847 - mse: 1.0006\n",
      "Epoch 943/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 180.8378 - mse: 1.2476\n",
      "Epoch 944/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 216.6452 - mse: 3.7974\n",
      "Epoch 945/1500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 219.5796 - mse: 3.8853\n",
      "Epoch 946/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 167.9185 - mse: 1.6958\n",
      "Epoch 947/1500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 170.5344 - mse: 1.2608\n",
      "Epoch 948/1500\n",
      "32/32 [==============================] - 0s 114us/step - loss: 180.4030 - mse: 1.2207\n",
      "Epoch 949/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 183.0447 - mse: 1.5280\n",
      "Epoch 950/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 177.0371 - mse: 1.9330\n",
      "Epoch 951/1500\n",
      "32/32 [==============================] - 0s 131us/step - loss: 180.7883 - mse: 2.0021\n",
      "Epoch 952/1500\n",
      "32/32 [==============================] - 0s 131us/step - loss: 198.7449 - mse: 2.7206\n",
      "Epoch 953/1500\n",
      "32/32 [==============================] - 0s 128us/step - loss: 175.5037 - mse: 1.2586\n",
      "Epoch 954/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 209.5708 - mse: 3.0960\n",
      "Epoch 955/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 188.4486 - mse: 1.1996\n",
      "Epoch 956/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 181.5470 - mse: 1.7728\n",
      "Epoch 957/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 182.8170 - mse: 1.5272\n",
      "Epoch 958/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 177.3491 - mse: 1.5983\n",
      "Epoch 959/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 185.6708 - mse: 1.6833\n",
      "Epoch 960/1500\n",
      "32/32 [==============================] - 0s 132us/step - loss: 176.4696 - mse: 1.4185\n",
      "Epoch 961/1500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 190.3365 - mse: 1.7878\n",
      "Epoch 962/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 188.6706 - mse: 2.6154\n",
      "Epoch 963/1500\n",
      "32/32 [==============================] - 0s 130us/step - loss: 193.8589 - mse: 2.1766\n",
      "Epoch 964/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 212.4254 - mse: 3.3698\n",
      "Epoch 965/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 182.7503 - mse: 1.1323\n",
      "Epoch 966/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 177.1532 - mse: 1.5301\n",
      "Epoch 967/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 181.9644 - mse: 2.0781\n",
      "Epoch 968/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 175.4213 - mse: 1.4020\n",
      "Epoch 969/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 167.0491 - mse: 1.2694\n",
      "Epoch 970/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 169.7202 - mse: 1.0791\n",
      "Epoch 971/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 176.6803 - mse: 1.8039\n",
      "Epoch 972/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 177.2514 - mse: 1.8239\n",
      "Epoch 973/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 191.3266 - mse: 1.7998\n",
      "Epoch 974/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 186.6792 - mse: 2.4306\n",
      "Epoch 975/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 210.3583 - mse: 4.0133\n",
      "Epoch 976/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 183.9243 - mse: 1.8850\n",
      "Epoch 977/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 183.7249 - mse: 1.5820\n",
      "Epoch 978/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 195.9631 - mse: 2.3809\n",
      "Epoch 979/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 174.5474 - mse: 1.5431\n",
      "Epoch 980/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 220.1856 - mse: 3.9251\n",
      "Epoch 981/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 161.3901 - mse: 1.2524\n",
      "Epoch 982/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 179.7408 - mse: 1.7880\n",
      "Epoch 983/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 169.0744 - mse: 1.0942\n",
      "Epoch 984/1500\n",
      "32/32 [==============================] - 0s 133us/step - loss: 169.4738 - mse: 1.5406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 192.3599 - mse: 2.2119\n",
      "Epoch 986/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 168.9264 - mse: 1.4312\n",
      "Epoch 987/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 175.2892 - mse: 1.5606\n",
      "Epoch 988/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 181.6537 - mse: 1.9195\n",
      "Epoch 989/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 165.3883 - mse: 1.5395\n",
      "Epoch 990/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 235.6187 - mse: 5.2588\n",
      "Epoch 991/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 195.3798 - mse: 2.7009\n",
      "Epoch 992/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 202.1396 - mse: 3.1098\n",
      "Epoch 993/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 177.1858 - mse: 1.8785\n",
      "Epoch 994/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 190.0911 - mse: 2.2728\n",
      "Epoch 995/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 239.7978 - mse: 5.7558\n",
      "Epoch 996/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 175.8470 - mse: 1.2830\n",
      "Epoch 997/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 184.3092 - mse: 1.6313\n",
      "Epoch 998/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 180.8699 - mse: 2.1806\n",
      "Epoch 999/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 294.9203 - mse: 9.7085\n",
      "Epoch 1000/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 189.7295 - mse: 1.3526\n",
      "Epoch 1001/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 197.2876 - mse: 3.8700\n",
      "Epoch 1002/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 167.3145 - mse: 1.1037\n",
      "Epoch 1003/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 190.4659 - mse: 2.7893\n",
      "Epoch 1004/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 244.8135 - mse: 5.9055\n",
      "Epoch 1005/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 180.0410 - mse: 1.1442\n",
      "Epoch 1006/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 200.6373 - mse: 3.0705\n",
      "Epoch 1007/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 232.0424 - mse: 5.0883\n",
      "Epoch 1008/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 204.0293 - mse: 2.3697\n",
      "Epoch 1009/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 175.3726 - mse: 1.6935\n",
      "Epoch 1010/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 192.8989 - mse: 1.9178\n",
      "Epoch 1011/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 179.0354 - mse: 1.8578\n",
      "Epoch 1012/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 190.2673 - mse: 2.0390\n",
      "Epoch 1013/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 221.0370 - mse: 3.4189\n",
      "Epoch 1014/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 204.3890 - mse: 3.3752\n",
      "Epoch 1015/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 183.6453 - mse: 2.2543\n",
      "Epoch 1016/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 184.2297 - mse: 2.3172\n",
      "Epoch 1017/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 180.7306 - mse: 1.0027\n",
      "Epoch 1018/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 188.3828 - mse: 1.7981\n",
      "Epoch 1019/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 181.5949 - mse: 2.2588\n",
      "Epoch 1020/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 318.8564 - mse: 10.5441\n",
      "Epoch 1021/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 207.8053 - mse: 3.4974\n",
      "Epoch 1022/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 190.0883 - mse: 1.9061\n",
      "Epoch 1023/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 187.4512 - mse: 1.5637\n",
      "Epoch 1024/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 209.9457 - mse: 3.8717\n",
      "Epoch 1025/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 185.2958 - mse: 1.7492\n",
      "Epoch 1026/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 192.0876 - mse: 1.9966\n",
      "Epoch 1027/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 183.9403 - mse: 1.3049\n",
      "Epoch 1028/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 175.6624 - mse: 1.1606\n",
      "Epoch 1029/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 172.1420 - mse: 1.5126\n",
      "Epoch 1030/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 174.2997 - mse: 1.1158\n",
      "Epoch 1031/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 191.0175 - mse: 1.4829\n",
      "Epoch 1032/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 189.2779 - mse: 1.1815\n",
      "Epoch 1033/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 185.3997 - mse: 1.2119\n",
      "Epoch 1034/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 189.3090 - mse: 1.6813\n",
      "Epoch 1035/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 189.4054 - mse: 1.3240\n",
      "Epoch 1036/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 191.7765 - mse: 1.8146\n",
      "Epoch 1037/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 180.0243 - mse: 2.2458\n",
      "Epoch 1038/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 187.6861 - mse: 1.9632\n",
      "Epoch 1039/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 180.1879 - mse: 1.8911\n",
      "Epoch 1040/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 172.0141 - mse: 1.2212\n",
      "Epoch 1041/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 170.7982 - mse: 1.5336\n",
      "Epoch 1042/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 192.8843 - mse: 2.0965\n",
      "Epoch 1043/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 181.4368 - mse: 1.6233\n",
      "Epoch 1044/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 222.9189 - mse: 4.3465\n",
      "Epoch 1045/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 187.3463 - mse: 1.2065\n",
      "Epoch 1046/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 173.2264 - mse: 1.5875\n",
      "Epoch 1047/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 193.6044 - mse: 2.8047\n",
      "Epoch 1048/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 189.5615 - mse: 2.1446\n",
      "Epoch 1049/1500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 172.1410 - mse: 1.2730\n",
      "Epoch 1050/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 176.7437 - mse: 1.4409\n",
      "Epoch 1051/1500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 182.7929 - mse: 1.4880\n",
      "Epoch 1052/1500\n",
      "32/32 [==============================] - 0s 60us/step - loss: 180.7741 - mse: 1.6957\n",
      "Epoch 1053/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 175.6798 - mse: 1.2378\n",
      "Epoch 1054/1500\n",
      "32/32 [==============================] - 0s 68us/step - loss: 182.1277 - mse: 1.4034\n",
      "Epoch 1055/1500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 178.2661 - mse: 1.1721\n",
      "Epoch 1056/1500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 165.9011 - mse: 1.1780\n",
      "Epoch 1057/1500\n",
      "32/32 [==============================] - 0s 57us/step - loss: 205.4300 - mse: 2.9416\n",
      "Epoch 1058/1500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 165.2352 - mse: 0.9643\n",
      "Epoch 1059/1500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 193.4645 - mse: 1.9253\n",
      "Epoch 1060/1500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 187.1951 - mse: 2.4881\n",
      "Epoch 1061/1500\n",
      "32/32 [==============================] - 0s 68us/step - loss: 189.2898 - mse: 1.5002\n",
      "Epoch 1062/1500\n",
      "32/32 [==============================] - 0s 69us/step - loss: 191.4137 - mse: 2.1153\n",
      "Epoch 1063/1500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 174.6192 - mse: 1.6768\n",
      "Epoch 1064/1500\n",
      "32/32 [==============================] - 0s 67us/step - loss: 185.2420 - mse: 1.8596\n",
      "Epoch 1065/1500\n",
      "32/32 [==============================] - 0s 60us/step - loss: 180.2574 - mse: 2.7391\n",
      "Epoch 1066/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 89us/step - loss: 197.2460 - mse: 2.2741\n",
      "Epoch 1067/1500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 227.1915 - mse: 4.4032\n",
      "Epoch 1068/1500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 187.3708 - mse: 1.6839\n",
      "Epoch 1069/1500\n",
      "32/32 [==============================] - 0s 64us/step - loss: 180.6307 - mse: 1.7005\n",
      "Epoch 1070/1500\n",
      "32/32 [==============================] - 0s 60us/step - loss: 187.3643 - mse: 1.9954\n",
      "Epoch 1071/1500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 171.6364 - mse: 1.3595\n",
      "Epoch 1072/1500\n",
      "32/32 [==============================] - 0s 61us/step - loss: 200.7711 - mse: 2.6916\n",
      "Epoch 1073/1500\n",
      "32/32 [==============================] - 0s 61us/step - loss: 203.8299 - mse: 3.0700\n",
      "Epoch 1074/1500\n",
      "32/32 [==============================] - 0s 59us/step - loss: 186.8301 - mse: 1.7640\n",
      "Epoch 1075/1500\n",
      "32/32 [==============================] - 0s 57us/step - loss: 195.6740 - mse: 2.5363\n",
      "Epoch 1076/1500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 174.8667 - mse: 1.8796\n",
      "Epoch 1077/1500\n",
      "32/32 [==============================] - 0s 57us/step - loss: 243.7159 - mse: 5.2323\n",
      "Epoch 1078/1500\n",
      "32/32 [==============================] - 0s 58us/step - loss: 185.5793 - mse: 1.6019\n",
      "Epoch 1079/1500\n",
      "32/32 [==============================] - 0s 60us/step - loss: 179.3837 - mse: 1.5653\n",
      "Epoch 1080/1500\n",
      "32/32 [==============================] - 0s 58us/step - loss: 188.4548 - mse: 1.8820\n",
      "Epoch 1081/1500\n",
      "32/32 [==============================] - 0s 59us/step - loss: 179.0329 - mse: 1.7347\n",
      "Epoch 1082/1500\n",
      "32/32 [==============================] - 0s 60us/step - loss: 193.2331 - mse: 2.5791\n",
      "Epoch 1083/1500\n",
      "32/32 [==============================] - 0s 60us/step - loss: 199.2606 - mse: 2.2371\n",
      "Epoch 1084/1500\n",
      "32/32 [==============================] - 0s 62us/step - loss: 178.8839 - mse: 1.3205\n",
      "Epoch 1085/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 181.6174 - mse: 1.4937\n",
      "Epoch 1086/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 174.4451 - mse: 1.3216\n",
      "Epoch 1087/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 166.6343 - mse: 1.1570\n",
      "Epoch 1088/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 311.1878 - mse: 9.8418\n",
      "Epoch 1089/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 183.4281 - mse: 2.4961\n",
      "Epoch 1090/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 195.2317 - mse: 2.5724\n",
      "Epoch 1091/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 174.9390 - mse: 1.4324\n",
      "Epoch 1092/1500\n",
      "32/32 [==============================] - 0s 65us/step - loss: 193.7088 - mse: 3.2677\n",
      "Epoch 1093/1500\n",
      "32/32 [==============================] - 0s 63us/step - loss: 188.4345 - mse: 1.8178\n",
      "Epoch 1094/1500\n",
      "32/32 [==============================] - 0s 68us/step - loss: 189.0163 - mse: 1.7861\n",
      "Epoch 1095/1500\n",
      "32/32 [==============================] - 0s 69us/step - loss: 192.8055 - mse: 1.8777\n",
      "Epoch 1096/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 191.6975 - mse: 2.5151\n",
      "Epoch 1097/1500\n",
      "32/32 [==============================] - 0s 70us/step - loss: 191.3855 - mse: 2.0332\n",
      "Epoch 1098/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 174.2086 - mse: 1.2614\n",
      "Epoch 1099/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 272.1074 - mse: 6.8344\n",
      "Epoch 1100/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 169.9340 - mse: 1.1974\n",
      "Epoch 1101/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 180.3324 - mse: 1.1229\n",
      "Epoch 1102/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 165.8532 - mse: 1.0447\n",
      "Epoch 1103/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 179.1772 - mse: 1.2831\n",
      "Epoch 1104/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 180.8213 - mse: 1.8986\n",
      "Epoch 1105/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 211.8962 - mse: 3.7721\n",
      "Epoch 1106/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 184.9359 - mse: 1.4927\n",
      "Epoch 1107/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 186.3711 - mse: 2.1616\n",
      "Epoch 1108/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 195.0023 - mse: 2.8636\n",
      "Epoch 1109/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 165.8404 - mse: 1.4223\n",
      "Epoch 1110/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 244.2574 - mse: 5.5492\n",
      "Epoch 1111/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 181.9937 - mse: 1.8991\n",
      "Epoch 1112/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 217.7327 - mse: 3.4663\n",
      "Epoch 1113/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 176.3897 - mse: 1.7754\n",
      "Epoch 1114/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 188.2061 - mse: 1.3908\n",
      "Epoch 1115/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 188.3086 - mse: 1.9259\n",
      "Epoch 1116/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 176.7392 - mse: 1.3976\n",
      "Epoch 1117/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 237.4547 - mse: 5.0500\n",
      "Epoch 1118/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 203.4857 - mse: 3.0012\n",
      "Epoch 1119/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 523.7770 - mse: 22.5645\n",
      "Epoch 1120/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 180.6130 - mse: 1.3843\n",
      "Epoch 1121/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 210.1872 - mse: 2.7856\n",
      "Epoch 1122/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 205.5858 - mse: 2.3687\n",
      "Epoch 1123/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 225.4069 - mse: 3.9792\n",
      "Epoch 1124/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 168.7431 - mse: 1.5552\n",
      "Epoch 1125/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 231.3844 - mse: 5.1189\n",
      "Epoch 1126/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 190.5477 - mse: 1.5816\n",
      "Epoch 1127/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 206.7840 - mse: 2.9211\n",
      "Epoch 1128/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 217.8640 - mse: 3.7145\n",
      "Epoch 1129/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 174.4531 - mse: 1.6702\n",
      "Epoch 1130/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 221.3695 - mse: 3.9758\n",
      "Epoch 1131/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 198.1452 - mse: 3.1047\n",
      "Epoch 1132/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 181.2485 - mse: 1.9000\n",
      "Epoch 1133/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 197.3040 - mse: 1.5267\n",
      "Epoch 1134/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 204.5948 - mse: 3.0455\n",
      "Epoch 1135/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 177.1510 - mse: 1.3974\n",
      "Epoch 1136/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 200.7861 - mse: 2.4481\n",
      "Epoch 1137/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 180.8925 - mse: 1.8635\n",
      "Epoch 1138/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 190.1540 - mse: 2.5793\n",
      "Epoch 1139/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 182.3749 - mse: 1.7563\n",
      "Epoch 1140/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 177.7676 - mse: 1.4610\n",
      "Epoch 1141/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 195.7715 - mse: 1.6412\n",
      "Epoch 1142/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 181.8334 - mse: 2.0917\n",
      "Epoch 1143/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 190.8396 - mse: 2.5328\n",
      "Epoch 1144/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 189.9263 - mse: 2.4339\n",
      "Epoch 1145/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 226.9418 - mse: 4.3660\n",
      "Epoch 1146/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 205.2200 - mse: 2.4388\n",
      "Epoch 1147/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 170.7270 - mse: 1.0410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1148/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 188.7349 - mse: 1.0255\n",
      "Epoch 1149/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 235.9648 - mse: 4.2143\n",
      "Epoch 1150/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 179.8342 - mse: 1.6199\n",
      "Epoch 1151/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 194.0919 - mse: 2.0616\n",
      "Epoch 1152/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 190.8103 - mse: 2.1467\n",
      "Epoch 1153/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 223.5460 - mse: 3.8440\n",
      "Epoch 1154/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 199.0035 - mse: 2.8232\n",
      "Epoch 1155/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 194.9099 - mse: 2.4283\n",
      "Epoch 1156/1500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 190.6445 - mse: 2.4470\n",
      "Epoch 1157/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 175.3872 - mse: 1.3934\n",
      "Epoch 1158/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 216.4552 - mse: 3.2310\n",
      "Epoch 1159/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 190.5221 - mse: 1.7268\n",
      "Epoch 1160/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 183.7604 - mse: 1.4747\n",
      "Epoch 1161/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 180.9045 - mse: 1.2013\n",
      "Epoch 1162/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 200.9807 - mse: 3.1053\n",
      "Epoch 1163/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 169.1998 - mse: 1.2364\n",
      "Epoch 1164/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 195.0707 - mse: 1.6007\n",
      "Epoch 1165/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 184.2289 - mse: 1.3525\n",
      "Epoch 1166/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 188.3132 - mse: 1.6636\n",
      "Epoch 1167/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 182.0738 - mse: 1.9123\n",
      "Epoch 1168/1500\n",
      "32/32 [==============================] - 0s 119us/step - loss: 199.6150 - mse: 2.3296\n",
      "Epoch 1169/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 189.8239 - mse: 1.5348\n",
      "Epoch 1170/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 175.2880 - mse: 1.3746\n",
      "Epoch 1171/1500\n",
      "32/32 [==============================] - 0s 125us/step - loss: 185.7200 - mse: 1.3251\n",
      "Epoch 1172/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 180.8618 - mse: 1.5700\n",
      "Epoch 1173/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 166.6432 - mse: 1.0012\n",
      "Epoch 1174/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 181.4325 - mse: 1.7894\n",
      "Epoch 1175/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 204.0638 - mse: 1.9822\n",
      "Epoch 1176/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 210.0522 - mse: 2.9957\n",
      "Epoch 1177/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 197.6905 - mse: 1.8656\n",
      "Epoch 1178/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 186.6246 - mse: 2.3911\n",
      "Epoch 1179/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 206.4245 - mse: 3.0620\n",
      "Epoch 1180/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 178.0292 - mse: 1.2647\n",
      "Epoch 1181/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 189.3231 - mse: 2.4636\n",
      "Epoch 1182/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 199.4021 - mse: 3.4884\n",
      "Epoch 1183/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 183.4765 - mse: 1.4949\n",
      "Epoch 1184/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 198.3007 - mse: 2.8634\n",
      "Epoch 1185/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 192.3564 - mse: 2.0570\n",
      "Epoch 1186/1500\n",
      "32/32 [==============================] - 0s 127us/step - loss: 187.0909 - mse: 1.5801\n",
      "Epoch 1187/1500\n",
      "32/32 [==============================] - 0s 124us/step - loss: 227.3929 - mse: 4.7422\n",
      "Epoch 1188/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 204.5572 - mse: 2.6898\n",
      "Epoch 1189/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 259.6593 - mse: 7.3063\n",
      "Epoch 1190/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 182.1804 - mse: 1.7632\n",
      "Epoch 1191/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 194.9419 - mse: 2.0852\n",
      "Epoch 1192/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 218.8520 - mse: 3.9314\n",
      "Epoch 1193/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 190.5530 - mse: 1.8705\n",
      "Epoch 1194/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 231.5452 - mse: 4.6621\n",
      "Epoch 1195/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 190.2805 - mse: 1.8985\n",
      "Epoch 1196/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 179.0738 - mse: 0.9500\n",
      "Epoch 1197/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 171.7242 - mse: 1.4581\n",
      "Epoch 1198/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 175.6564 - mse: 1.7667\n",
      "Epoch 1199/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 192.0345 - mse: 1.1249\n",
      "Epoch 1200/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 172.7301 - mse: 1.4970\n",
      "Epoch 1201/1500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 182.7379 - mse: 2.1666\n",
      "Epoch 1202/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 180.3990 - mse: 1.7371\n",
      "Epoch 1203/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 203.8487 - mse: 2.7135\n",
      "Epoch 1204/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 183.8302 - mse: 1.6623\n",
      "Epoch 1205/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 185.3238 - mse: 1.8501\n",
      "Epoch 1206/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 162.1350 - mse: 1.3875\n",
      "Epoch 1207/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 200.0330 - mse: 1.9242\n",
      "Epoch 1208/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 185.0190 - mse: 1.5226\n",
      "Epoch 1209/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 195.4497 - mse: 2.9273\n",
      "Epoch 1210/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 200.0268 - mse: 2.9932\n",
      "Epoch 1211/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 175.1847 - mse: 1.3108\n",
      "Epoch 1212/1500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 200.0194 - mse: 1.8759\n",
      "Epoch 1213/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 190.8636 - mse: 1.5865\n",
      "Epoch 1214/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 182.2372 - mse: 1.7988\n",
      "Epoch 1215/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 280.6636 - mse: 8.2024\n",
      "Epoch 1216/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 188.0202 - mse: 1.8274\n",
      "Epoch 1217/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 176.7838 - mse: 1.0320\n",
      "Epoch 1218/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 204.2921 - mse: 2.7239\n",
      "Epoch 1219/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 231.8041 - mse: 4.3297\n",
      "Epoch 1220/1500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 348.9850 - mse: 11.9426\n",
      "Epoch 1221/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 191.7885 - mse: 1.3247\n",
      "Epoch 1222/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 177.6217 - mse: 1.3468\n",
      "Epoch 1223/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 183.0905 - mse: 1.6048\n",
      "Epoch 1224/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 183.3314 - mse: 1.9490\n",
      "Epoch 1225/1500\n",
      "32/32 [==============================] - 0s 142us/step - loss: 190.3103 - mse: 1.9304\n",
      "Epoch 1226/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 550.3298 - mse: 24.7697\n",
      "Epoch 1227/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 207.3034 - mse: 2.1050\n",
      "Epoch 1228/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 204.5894 - mse: 2.5838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1229/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 211.1196 - mse: 2.9278\n",
      "Epoch 1230/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 192.3723 - mse: 3.0928\n",
      "Epoch 1231/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 188.8461 - mse: 2.4210\n",
      "Epoch 1232/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 189.5058 - mse: 1.8337\n",
      "Epoch 1233/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 242.4512 - mse: 6.4529\n",
      "Epoch 1234/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 191.0722 - mse: 1.8699\n",
      "Epoch 1235/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 187.7622 - mse: 1.7501\n",
      "Epoch 1236/1500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 206.8532 - mse: 2.3594\n",
      "Epoch 1237/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 183.7952 - mse: 1.8624\n",
      "Epoch 1238/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 216.3147 - mse: 3.5948\n",
      "Epoch 1239/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 206.5757 - mse: 2.3331\n",
      "Epoch 1240/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 184.1645 - mse: 1.5506\n",
      "Epoch 1241/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 189.4733 - mse: 1.9043\n",
      "Epoch 1242/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 205.8467 - mse: 1.8171\n",
      "Epoch 1243/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 157.3701 - mse: 1.2561\n",
      "Epoch 1244/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 181.9885 - mse: 1.4559\n",
      "Epoch 1245/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 187.8161 - mse: 1.3197\n",
      "Epoch 1246/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 208.4479 - mse: 3.2187\n",
      "Epoch 1247/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 186.6998 - mse: 1.5008\n",
      "Epoch 1248/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 195.2639 - mse: 1.8008\n",
      "Epoch 1249/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 176.7292 - mse: 1.0777\n",
      "Epoch 1250/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 177.9891 - mse: 1.7362\n",
      "Epoch 1251/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 181.2334 - mse: 1.1853\n",
      "Epoch 1252/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 187.5982 - mse: 1.0095\n",
      "Epoch 1253/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 181.9571 - mse: 1.9882\n",
      "Epoch 1254/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 194.1428 - mse: 2.5819\n",
      "Epoch 1255/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 176.7419 - mse: 1.3877\n",
      "Epoch 1256/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 203.0223 - mse: 3.4030\n",
      "Epoch 1257/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 178.8445 - mse: 1.2915\n",
      "Epoch 1258/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 188.6959 - mse: 2.2070\n",
      "Epoch 1259/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 189.5560 - mse: 1.7971\n",
      "Epoch 1260/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 188.0411 - mse: 2.1921\n",
      "Epoch 1261/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 221.8833 - mse: 4.1763\n",
      "Epoch 1262/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 168.3021 - mse: 1.2000\n",
      "Epoch 1263/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 182.6995 - mse: 2.0046\n",
      "Epoch 1264/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 179.7525 - mse: 2.1725\n",
      "Epoch 1265/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 259.3343 - mse: 6.4863\n",
      "Epoch 1266/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 232.6963 - mse: 4.0604\n",
      "Epoch 1267/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 169.1584 - mse: 1.2437\n",
      "Epoch 1268/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 189.3588 - mse: 2.5688\n",
      "Epoch 1269/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 212.7401 - mse: 3.2592\n",
      "Epoch 1270/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 202.0230 - mse: 2.0861\n",
      "Epoch 1271/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 213.4985 - mse: 3.6884\n",
      "Epoch 1272/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 177.1322 - mse: 1.5279\n",
      "Epoch 1273/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 206.5048 - mse: 3.2350\n",
      "Epoch 1274/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 219.9807 - mse: 3.8605\n",
      "Epoch 1275/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 176.3914 - mse: 1.1459\n",
      "Epoch 1276/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 174.0906 - mse: 1.5201\n",
      "Epoch 1277/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 175.2203 - mse: 1.3990\n",
      "Epoch 1278/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 179.4286 - mse: 2.7393\n",
      "Epoch 1279/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 205.1906 - mse: 2.6839\n",
      "Epoch 1280/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 201.1879 - mse: 2.0976\n",
      "Epoch 1281/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 207.7817 - mse: 2.9747\n",
      "Epoch 1282/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 182.8334 - mse: 1.9871\n",
      "Epoch 1283/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 187.4747 - mse: 1.7277\n",
      "Epoch 1284/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 207.8742 - mse: 2.8424\n",
      "Epoch 1285/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 205.8095 - mse: 3.3476\n",
      "Epoch 1286/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 175.8155 - mse: 2.0270\n",
      "Epoch 1287/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 191.3125 - mse: 2.7196\n",
      "Epoch 1288/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 200.4131 - mse: 2.8574\n",
      "Epoch 1289/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 182.8603 - mse: 1.9315\n",
      "Epoch 1290/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 235.8072 - mse: 5.2187\n",
      "Epoch 1291/1500\n",
      "32/32 [==============================] - 0s 72us/step - loss: 201.3854 - mse: 2.8471\n",
      "Epoch 1292/1500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 188.5780 - mse: 1.6273\n",
      "Epoch 1293/1500\n",
      "32/32 [==============================] - 0s 132us/step - loss: 180.0465 - mse: 1.4118\n",
      "Epoch 1294/1500\n",
      "32/32 [==============================] - 0s 75us/step - loss: 174.0042 - mse: 1.3227\n",
      "Epoch 1295/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 211.8126 - mse: 3.1077\n",
      "Epoch 1296/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 190.9518 - mse: 2.3236\n",
      "Epoch 1297/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 196.9342 - mse: 3.1016\n",
      "Epoch 1298/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 187.2262 - mse: 1.9259\n",
      "Epoch 1299/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 189.9382 - mse: 0.9415\n",
      "Epoch 1300/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 193.3800 - mse: 1.0696\n",
      "Epoch 1301/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 182.1039 - mse: 1.3009\n",
      "Epoch 1302/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 193.5641 - mse: 2.2688\n",
      "Epoch 1303/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 204.3491 - mse: 2.9941\n",
      "Epoch 1304/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 190.3555 - mse: 2.3858\n",
      "Epoch 1305/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 177.9768 - mse: 1.5229\n",
      "Epoch 1306/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 200.9145 - mse: 2.6880\n",
      "Epoch 1307/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 190.0669 - mse: 1.7954\n",
      "Epoch 1308/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 171.3248 - mse: 1.2753\n",
      "Epoch 1309/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 166.9500 - mse: 1.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1310/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 171.4026 - mse: 1.0236\n",
      "Epoch 1311/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 195.1048 - mse: 2.3950\n",
      "Epoch 1312/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 188.6228 - mse: 2.2293\n",
      "Epoch 1313/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 235.2676 - mse: 4.9743\n",
      "Epoch 1314/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 191.4638 - mse: 1.7426\n",
      "Epoch 1315/1500\n",
      "32/32 [==============================] - 0s 94us/step - loss: 200.4069 - mse: 2.9775\n",
      "Epoch 1316/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 199.8000 - mse: 2.5267\n",
      "Epoch 1317/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 178.1133 - mse: 1.3420\n",
      "Epoch 1318/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 216.2389 - mse: 3.2829\n",
      "Epoch 1319/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 189.8830 - mse: 2.5739\n",
      "Epoch 1320/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 189.5664 - mse: 1.1962\n",
      "Epoch 1321/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 187.2137 - mse: 1.6979\n",
      "Epoch 1322/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 166.1497 - mse: 1.4995\n",
      "Epoch 1323/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 186.5641 - mse: 2.1646\n",
      "Epoch 1324/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 180.2155 - mse: 1.0398\n",
      "Epoch 1325/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 176.6657 - mse: 1.7686\n",
      "Epoch 1326/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 193.0267 - mse: 2.5139\n",
      "Epoch 1327/1500\n",
      "32/32 [==============================] - 0s 76us/step - loss: 197.0150 - mse: 2.7176\n",
      "Epoch 1328/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 198.6176 - mse: 3.0299\n",
      "Epoch 1329/1500\n",
      "32/32 [==============================] - 0s 71us/step - loss: 213.8340 - mse: 3.4519\n",
      "Epoch 1330/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 178.8296 - mse: 2.2442\n",
      "Epoch 1331/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 185.6119 - mse: 1.8149\n",
      "Epoch 1332/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 212.6010 - mse: 3.4815\n",
      "Epoch 1333/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 176.7449 - mse: 1.4409\n",
      "Epoch 1334/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 173.2534 - mse: 2.0387\n",
      "Epoch 1335/1500\n",
      "32/32 [==============================] - 0s 74us/step - loss: 236.4229 - mse: 5.2267\n",
      "Epoch 1336/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 190.0922 - mse: 1.7907\n",
      "Epoch 1337/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 220.0744 - mse: 4.9203\n",
      "Epoch 1338/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 209.8775 - mse: 3.2815\n",
      "Epoch 1339/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 172.4155 - mse: 1.1290\n",
      "Epoch 1340/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 177.5043 - mse: 1.2083\n",
      "Epoch 1341/1500\n",
      "32/32 [==============================] - 0s 77us/step - loss: 191.0477 - mse: 1.7587\n",
      "Epoch 1342/1500\n",
      "32/32 [==============================] - 0s 73us/step - loss: 180.8666 - mse: 1.8313\n",
      "Epoch 1343/1500\n",
      "32/32 [==============================] - 0s 91us/step - loss: 192.5084 - mse: 1.8922\n",
      "Epoch 1344/1500\n",
      "32/32 [==============================] - 0s 86us/step - loss: 279.2330 - mse: 8.2690\n",
      "Epoch 1345/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 197.4085 - mse: 2.7578\n",
      "Epoch 1346/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 188.0633 - mse: 1.5721\n",
      "Epoch 1347/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 171.7181 - mse: 1.2489\n",
      "Epoch 1348/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 193.7041 - mse: 1.9786\n",
      "Epoch 1349/1500\n",
      "32/32 [==============================] - 0s 123us/step - loss: 186.6748 - mse: 2.2315\n",
      "Epoch 1350/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 207.2740 - mse: 4.0796\n",
      "Epoch 1351/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 237.1048 - mse: 5.8809\n",
      "Epoch 1352/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 180.8874 - mse: 1.4357\n",
      "Epoch 1353/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 192.9831 - mse: 1.5800\n",
      "Epoch 1354/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 196.0643 - mse: 2.4131\n",
      "Epoch 1355/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 187.9847 - mse: 2.3832\n",
      "Epoch 1356/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 169.6512 - mse: 1.6787\n",
      "Epoch 1357/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 209.1226 - mse: 2.9366\n",
      "Epoch 1358/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 169.2684 - mse: 1.6389\n",
      "Epoch 1359/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 214.8736 - mse: 3.8205\n",
      "Epoch 1360/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 220.8504 - mse: 4.2290\n",
      "Epoch 1361/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 171.9808 - mse: 1.7747\n",
      "Epoch 1362/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 220.1901 - mse: 4.1517\n",
      "Epoch 1363/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 179.5633 - mse: 1.1850\n",
      "Epoch 1364/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 196.2746 - mse: 2.4616\n",
      "Epoch 1365/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 302.7354 - mse: 10.0869\n",
      "Epoch 1366/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 191.2774 - mse: 2.1691\n",
      "Epoch 1367/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 184.5016 - mse: 1.5284\n",
      "Epoch 1368/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 217.6917 - mse: 3.5454\n",
      "Epoch 1369/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 197.3490 - mse: 2.7831\n",
      "Epoch 1370/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 209.2116 - mse: 3.8441\n",
      "Epoch 1371/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 187.4817 - mse: 1.5095\n",
      "Epoch 1372/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 195.2140 - mse: 2.2092\n",
      "Epoch 1373/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 183.2259 - mse: 1.5004\n",
      "Epoch 1374/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 183.0258 - mse: 1.6618\n",
      "Epoch 1375/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 178.6792 - mse: 1.1020\n",
      "Epoch 1376/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 195.7822 - mse: 2.1378\n",
      "Epoch 1377/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 204.3747 - mse: 2.7919\n",
      "Epoch 1378/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 332.3087 - mse: 11.0885\n",
      "Epoch 1379/1500\n",
      "32/32 [==============================] - 0s 137us/step - loss: 204.3495 - mse: 2.7030\n",
      "Epoch 1380/1500\n",
      "32/32 [==============================] - 0s 141us/step - loss: 186.9416 - mse: 2.0318\n",
      "Epoch 1381/1500\n",
      "32/32 [==============================] - 0s 136us/step - loss: 220.8772 - mse: 3.3689\n",
      "Epoch 1382/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 187.1887 - mse: 1.2607\n",
      "Epoch 1383/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 190.8086 - mse: 2.6034\n",
      "Epoch 1384/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 184.4475 - mse: 1.3289\n",
      "Epoch 1385/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 184.5758 - mse: 1.4885\n",
      "Epoch 1386/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 179.5972 - mse: 1.1764\n",
      "Epoch 1387/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 188.9140 - mse: 1.6775\n",
      "Epoch 1388/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 198.2786 - mse: 2.2895\n",
      "Epoch 1389/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 172.0637 - mse: 1.1141\n",
      "Epoch 1390/1500\n",
      "32/32 [==============================] - 0s 117us/step - loss: 208.4794 - mse: 2.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1391/1500\n",
      "32/32 [==============================] - 0s 126us/step - loss: 208.6311 - mse: 2.7446\n",
      "Epoch 1392/1500\n",
      "32/32 [==============================] - 0s 167us/step - loss: 179.1353 - mse: 1.2568\n",
      "Epoch 1393/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 273.7886 - mse: 8.3752\n",
      "Epoch 1394/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 185.0314 - mse: 1.7264\n",
      "Epoch 1395/1500\n",
      "32/32 [==============================] - 0s 104us/step - loss: 194.8060 - mse: 1.9969\n",
      "Epoch 1396/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 192.8954 - mse: 2.6366\n",
      "Epoch 1397/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 215.1479 - mse: 3.3201\n",
      "Epoch 1398/1500\n",
      "32/32 [==============================] - 0s 109us/step - loss: 180.8470 - mse: 1.3271\n",
      "Epoch 1399/1500\n",
      "32/32 [==============================] - 0s 145us/step - loss: 369.7463 - mse: 13.5120\n",
      "Epoch 1400/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 172.8130 - mse: 1.1791\n",
      "Epoch 1401/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 185.5420 - mse: 2.3208\n",
      "Epoch 1402/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 175.2717 - mse: 1.2314\n",
      "Epoch 1403/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 182.1677 - mse: 0.9686\n",
      "Epoch 1404/1500\n",
      "32/32 [==============================] - 0s 88us/step - loss: 197.1795 - mse: 1.8770\n",
      "Epoch 1405/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 265.6056 - mse: 6.8446\n",
      "Epoch 1406/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 220.8251 - mse: 3.6902\n",
      "Epoch 1407/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 210.4315 - mse: 3.4342\n",
      "Epoch 1408/1500\n",
      "32/32 [==============================] - 0s 106us/step - loss: 194.3033 - mse: 2.8347\n",
      "Epoch 1409/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 188.3602 - mse: 1.8945\n",
      "Epoch 1410/1500\n",
      "32/32 [==============================] - 0s 115us/step - loss: 195.6205 - mse: 1.7917\n",
      "Epoch 1411/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 186.1450 - mse: 1.6035\n",
      "Epoch 1412/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 195.1652 - mse: 2.4944\n",
      "Epoch 1413/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 315.5100 - mse: 9.6158\n",
      "Epoch 1414/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 221.3662 - mse: 3.9009\n",
      "Epoch 1415/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 181.1543 - mse: 1.1267\n",
      "Epoch 1416/1500\n",
      "32/32 [==============================] - 0s 112us/step - loss: 188.7449 - mse: 1.9334\n",
      "Epoch 1417/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 179.2960 - mse: 1.3528\n",
      "Epoch 1418/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 212.5997 - mse: 2.6464\n",
      "Epoch 1419/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 224.0490 - mse: 4.5221\n",
      "Epoch 1420/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 178.8824 - mse: 1.2164\n",
      "Epoch 1421/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 183.5199 - mse: 1.9363\n",
      "Epoch 1422/1500\n",
      "32/32 [==============================] - 0s 84us/step - loss: 184.1286 - mse: 1.2148\n",
      "Epoch 1423/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 175.4997 - mse: 1.4667\n",
      "Epoch 1424/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 200.8385 - mse: 1.9651\n",
      "Epoch 1425/1500\n",
      "32/32 [==============================] - 0s 92us/step - loss: 183.0504 - mse: 1.2553\n",
      "Epoch 1426/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 194.9705 - mse: 1.7665\n",
      "Epoch 1427/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 195.0492 - mse: 2.8644\n",
      "Epoch 1428/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 194.8161 - mse: 2.2218\n",
      "Epoch 1429/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 246.9848 - mse: 5.7271\n",
      "Epoch 1430/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 176.3144 - mse: 1.3428\n",
      "Epoch 1431/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 218.9818 - mse: 3.2625\n",
      "Epoch 1432/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 177.0516 - mse: 1.1620\n",
      "Epoch 1433/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 211.5438 - mse: 2.9475\n",
      "Epoch 1434/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 212.7900 - mse: 3.5097\n",
      "Epoch 1435/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 171.5718 - mse: 0.8987\n",
      "Epoch 1436/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 180.4384 - mse: 1.2170\n",
      "Epoch 1437/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 231.6823 - mse: 4.7796\n",
      "Epoch 1438/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 270.1440 - mse: 6.8614\n",
      "Epoch 1439/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 203.8746 - mse: 2.3127\n",
      "Epoch 1440/1500\n",
      "32/32 [==============================] - 0s 111us/step - loss: 198.1194 - mse: 2.0284\n",
      "Epoch 1441/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 205.7409 - mse: 1.6645\n",
      "Epoch 1442/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 179.9791 - mse: 2.1457\n",
      "Epoch 1443/1500\n",
      "32/32 [==============================] - 0s 113us/step - loss: 183.8012 - mse: 1.9018\n",
      "Epoch 1444/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 190.1215 - mse: 2.0217\n",
      "Epoch 1445/1500\n",
      "32/32 [==============================] - 0s 103us/step - loss: 176.0474 - mse: 1.4240\n",
      "Epoch 1446/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 201.3755 - mse: 2.8354\n",
      "Epoch 1447/1500\n",
      "32/32 [==============================] - 0s 85us/step - loss: 202.2771 - mse: 1.9332\n",
      "Epoch 1448/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 229.7473 - mse: 4.2379\n",
      "Epoch 1449/1500\n",
      "32/32 [==============================] - 0s 82us/step - loss: 194.2307 - mse: 2.2287\n",
      "Epoch 1450/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 178.4048 - mse: 1.9306\n",
      "Epoch 1451/1500\n",
      "32/32 [==============================] - 0s 80us/step - loss: 180.1926 - mse: 1.8606\n",
      "Epoch 1452/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 182.7697 - mse: 1.3360\n",
      "Epoch 1453/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 227.4102 - mse: 4.6888\n",
      "Epoch 1454/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 194.8269 - mse: 1.8079\n",
      "Epoch 1455/1500\n",
      "32/32 [==============================] - 0s 81us/step - loss: 241.2298 - mse: 5.3377\n",
      "Epoch 1456/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 198.8201 - mse: 2.7319\n",
      "Epoch 1457/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 183.2388 - mse: 2.1449\n",
      "Epoch 1458/1500\n",
      "32/32 [==============================] - 0s 89us/step - loss: 198.4942 - mse: 3.1595\n",
      "Epoch 1459/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 188.9838 - mse: 1.7536\n",
      "Epoch 1460/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 212.7017 - mse: 3.6231\n",
      "Epoch 1461/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 207.1328 - mse: 3.2958\n",
      "Epoch 1462/1500\n",
      "32/32 [==============================] - 0s 97us/step - loss: 193.8000 - mse: 1.8140\n",
      "Epoch 1463/1500\n",
      "32/32 [==============================] - 0s 118us/step - loss: 196.1566 - mse: 1.1468\n",
      "Epoch 1464/1500\n",
      "32/32 [==============================] - 0s 105us/step - loss: 203.4514 - mse: 3.6149\n",
      "Epoch 1465/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 207.8050 - mse: 2.9660\n",
      "Epoch 1466/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 179.5863 - mse: 1.1655\n",
      "Epoch 1467/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 198.5560 - mse: 2.9840\n",
      "Epoch 1468/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 229.0582 - mse: 4.8076\n",
      "Epoch 1469/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 178.0533 - mse: 1.4150\n",
      "Epoch 1470/1500\n",
      "32/32 [==============================] - 0s 93us/step - loss: 211.2296 - mse: 3.1405\n",
      "Epoch 1471/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 206.6043 - mse: 1.7829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1472/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 206.8476 - mse: 2.7027\n",
      "Epoch 1473/1500\n",
      "32/32 [==============================] - 0s 100us/step - loss: 180.2484 - mse: 1.2243\n",
      "Epoch 1474/1500\n",
      "32/32 [==============================] - 0s 108us/step - loss: 183.7152 - mse: 1.4511\n",
      "Epoch 1475/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 194.7201 - mse: 2.1446\n",
      "Epoch 1476/1500\n",
      "32/32 [==============================] - 0s 107us/step - loss: 191.0482 - mse: 1.9368\n",
      "Epoch 1477/1500\n",
      "32/32 [==============================] - 0s 98us/step - loss: 213.1235 - mse: 2.0915\n",
      "Epoch 1478/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 215.2411 - mse: 3.0174\n",
      "Epoch 1479/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 202.6484 - mse: 2.3664\n",
      "Epoch 1480/1500\n",
      "32/32 [==============================] - 0s 116us/step - loss: 176.8397 - mse: 1.3592\n",
      "Epoch 1481/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 188.7730 - mse: 2.1711\n",
      "Epoch 1482/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 195.2424 - mse: 1.3456\n",
      "Epoch 1483/1500\n",
      "32/32 [==============================] - 0s 90us/step - loss: 194.4969 - mse: 2.3738\n",
      "Epoch 1484/1500\n",
      "32/32 [==============================] - 0s 110us/step - loss: 178.8195 - mse: 1.1479\n",
      "Epoch 1485/1500\n",
      "32/32 [==============================] - 0s 102us/step - loss: 192.7731 - mse: 2.2528\n",
      "Epoch 1486/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 221.1037 - mse: 4.9770\n",
      "Epoch 1487/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 208.6800 - mse: 2.6659\n",
      "Epoch 1488/1500\n",
      "32/32 [==============================] - 0s 96us/step - loss: 200.0678 - mse: 2.5061\n",
      "Epoch 1489/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 204.0224 - mse: 2.1731\n",
      "Epoch 1490/1500\n",
      "32/32 [==============================] - 0s 87us/step - loss: 313.3673 - mse: 9.9586\n",
      "Epoch 1491/1500\n",
      "32/32 [==============================] - 0s 101us/step - loss: 200.5431 - mse: 2.1575\n",
      "Epoch 1492/1500\n",
      "32/32 [==============================] - 0s 121us/step - loss: 174.3414 - mse: 1.1658\n",
      "Epoch 1493/1500\n",
      "32/32 [==============================] - 0s 95us/step - loss: 189.4497 - mse: 2.4721\n",
      "Epoch 1494/1500\n",
      "32/32 [==============================] - 0s 122us/step - loss: 191.2531 - mse: 1.7957\n",
      "Epoch 1495/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 191.1917 - mse: 1.7542\n",
      "Epoch 1496/1500\n",
      "32/32 [==============================] - 0s 79us/step - loss: 205.8649 - mse: 2.5347\n",
      "Epoch 1497/1500\n",
      "32/32 [==============================] - 0s 99us/step - loss: 184.6144 - mse: 1.9159\n",
      "Epoch 1498/1500\n",
      "32/32 [==============================] - 0s 83us/step - loss: 210.1597 - mse: 2.5778\n",
      "Epoch 1499/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 174.6900 - mse: 1.0274\n",
      "Epoch 1500/1500\n",
      "32/32 [==============================] - 0s 78us/step - loss: 189.8789 - mse: 2.4540\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks, optimizers\n",
    "\n",
    "def neg_log_likelihood(y_obs, y_pred, sigma=noise):\n",
    "    dist = tfp.distributions.Normal(loc=y_pred, scale=sigma)\n",
    "    return K.sum(-dist.log_prob(y_obs))\n",
    "\n",
    "model.compile(loss=neg_log_likelihood, optimizer=optimizers.Adam(lr=0.03), metrics=['mse'])\n",
    "model.fit(X, y, batch_size=batch_size, epochs=1500, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'mixture_prior_params:0' shape=(3,) dtype=float32>,\n",
       " <tf.Variable 'dense_variational_1/kernel_mu:0' shape=(1, 20) dtype=float32>,\n",
       " <tf.Variable 'dense_variational_1/bias_mu:0' shape=(20,) dtype=float32>,\n",
       " <tf.Variable 'dense_variational_1/kernel_rho:0' shape=(1, 20) dtype=float32>,\n",
       " <tf.Variable 'dense_variational_1/bias_rho:0' shape=(20,) dtype=float32>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print({l.name: l.weights for l in model.layers})\n",
    "#model.layers[1].get_weights()\n",
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:16<00:00, 29.63it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "X_test = np.linspace(-1.5, 1.5, 1000).reshape(-1, 1)\n",
    "y_pred_list = []\n",
    "\n",
    "for i in tqdm.tqdm(range(500)):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "y_preds = np.concatenate(y_pred_list, axis=1)\n",
    "\n",
    "y_mean = np.mean(y_preds, axis=1)\n",
    "y_sigma = np.std(y_preds, axis=1)\n",
    "\n",
    "plt.plot(X_test, y_mean, 'r-', label='Predictive mean');\n",
    "plt.scatter(X, y, marker='+', label='Training data')\n",
    "plt.fill_between(X_test.ravel(), \n",
    "                 y_mean + 2 * y_sigma, \n",
    "                 y_mean - 2 * y_sigma, \n",
    "                 alpha=0.5, label='Epistemic uncertainty')\n",
    "plt.title('Prediction')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
